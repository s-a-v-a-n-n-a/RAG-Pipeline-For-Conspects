Сортировка выбором (англ. selection sort)  простой алгоритм сортировки со сложностью O(n^2), где n  количество элементов для сортировки.

 Алгоритм 
На каждом i-ом шаге алгоритма находим i-ый минимальный элемент и меняем его местами с i-ым элементом в массиве. Таким образом будет получен массив, отсортированный по неубыванию.

 Псевдокод 
Вариант 1.
Будем каждый раз проходить по всем еще не отсортированным элементам, и, как только найдем элемент меньше, чем первый из неотсортированных, поменяем их местами. Таким образом будет нужно O(n^2) обменов (для каждого i требуется O(n-i) обменов). 
  function selectionSort(T[n] a):
    for i = 0 to n - 2
      for j = i + 1 to n - 1
        if a[i] > a[j]
          swap(a[i], a[j])

Вариант 2.
Второй вариант немного более экономный. Здесь мы будем менять местами элементы только 1 раз для каждого i, всего будет нужно O(n) обменов. Для этого сначала мы будем проходить по всем еще не отсортированным элементам, искать минимальный, и только потом менять местами минимальный и первый из неотсортированных.

 function selectionSort(T[n] a):
    for i = 0 to n - 2
      min = i
      for j = i + 1 to n - 1
        if a[j] < a[min]
          min = j
      swap(a[i], a[min])

 Пример 

Пусть дана последовательность из 5 элементов 5, 4, 1, 2, 3. Будем выделять текущий элемент на каждом шаге фиолетовым цветом, а минимальный черным жирным.

 Массив Описание шагаПервый проход (текущий массив начинается с первого элемента) 5 4 1 2 3 Находим первый минимальный элемент  1  1 4 5 2 3 Меняем минимальный и первый элементы местамиВторой проход (текущий массив начинается со следующего элемента) 1 4 5 2 3 Находим следующий минимальный элемент  2  1 2 5 4 3 Меняем минимальный и второй элементы местамиТретий проход (текущий массив начинается со следующего элемента) 1 2 5 4 3 Находим следующий минимальный элемент  3  1 2 3 4 5 Меняем минимальный и третий элементы местамиЧетвертый проход (текущий массив начинается со следующего элемента) 1 2 3 4 5 Находим следующий минимальный элемент  4. Меняем его местами с самим собой. 1 2 3 4 5 Массив отсортирован

 См. также 
 Сортировка пузырьком
 Сортировка вставками
 Сортировка кучей
 Сортировка слиянием
 Быстрая сортировка
 Сортировка подсчетом
 Сортировка Шелла

 Источники информации  
Википедия  Сортировка выбором
Кормен Т., Лейзерсон Ч., Ривест Р., Штайн К. Алгоритмы: построение и анализ, 2-е издание. М.: Издательский дом "Вильямс", 2005. ISBN 5-8459-0857-4

Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Квадратичные сортировки-----Сортировка простыми обменами, сортировка пузырьком (англ. bubble sort) — один из квадратичных алгоритмов сортировки.

 Алгоритм 
Алгоритм состоит в повторяющихся проходах по сортируемому массиву. На каждой итерации последовательно сравниваются соседние элементы, и, если порядок в паре неверный, то элементы меняют местами. За каждый проход по массиву как минимум один элемент встает на свое место, поэтому необходимо совершить не более  n - 1  проходов, где  n  размер массива, чтобы отсортировать массив.

Ниже приведен псевдокод сортировки пузырьком, на вход которой подается массив  a[0..n - 1] .
 function bubbleSort(a):
   for i = 0 to n - 2
     for j = 0 to n - 2
       if a[j] > a[j + 1]
         swap(a[j], a[j + 1])

 Оптимизация 
 Можно заметить, что после  i -ой итерации внешнего цикла  i  последних элементов уже находятся на своих местах в отсортированном порядке, поэтому нет необходимости производить их сравнения друг с другом. Следовательно, внутренний цикл можно выполнять не до  n - 2 , а до  n - i - 2 .
 Также заметим, что если после выполнения внутреннего цикла не произошло ни одного обмена, то массив уже отсортирован, и продолжать что-то делать бессмысленно. Поэтому внутренний цикл можно выполнять не  n - 1  раз, а до тех пор, пока во внутреннем цикле происходят обмены.

При использовании первой оптимизации сортировка принимает следующий вид:
 function bubbleSort(a):
   for i = 0 to n - 2
     for j = 0 to n - i - 2
       if a[j] > a[j + 1]
         swap(a[j], a[j + 1])

При использовании же обеих оптимизаций сортировка пузырьком выглядит так:
 function bubbleSort(a):
   i = 0
   t = true
   while t
     t = false
     for j = 0 to n - i - 2
       if a[j] > a[j + 1]
         swap(a[j], a[j + 1])
         t = true
     i = i + 1

 Сложность 
В данной сортировке выполняются всего два различных вида операции: сравнение элементов и их обмен. Поэтому время всего алгоритма  T = T_1 + T_2 , где  T_1   время, затрачиваемое на сравнение элементов, а  T_2   время, за которое мы производим все необходимые обмены элементов.

Так как в алгоритме меняться местами могут только соседние элементы, то каждый обмен уменьшает количество инверсий на единицу. Следовательно, количество обменов равно количеству инверсий в исходном массиве вне зависимости от реализации сортировки. Максимальное количество инверсий содержится в массиве, элементы которого отсортированы по убыванию. Несложно посчитать, что количество инверсий в таком массиве  \frac {n (n - 1)} {2} . Получаем, что  T_2 = O(n^2) .

В неоптимизированной реализации на каждой итерации внутреннего цикла производятся  n - 1  сравнений, а так как внутренний цикл запускается также  n - 1  раз, то за весь алгоритм сортировки производятся  (n - 1)^2  сравнений.

В оптимизированной версии точное количество сравнений зависит от исходного массива. Известно, что худший случай равен  \frac {n (n - 1)} {2} , а лучший   n-1 . Следовательно,  T_1 = O(n^2) .

В итоге получаем  T = T_1 + T_2 = O(n^2) + O(n^2) = O(n^2) .

 Пример работы алгоритма 

Возьмём массив  [5, 1, 4, 2, 8]  и отсортируем значения по возрастанию, используя сортировку пузырьком. Выделены те элементы, которые сравниваются на данном этапе.

Первый проход:

 До После Описание шага 5 1 4 2 8 1 5 4 2 8 Здесь алгоритм сравнивает два первых элемента и меняет их местами. 1 5 4 2 8  1 4 5 2 8 Меняет местами, так как 5 > 4 1 4 5 2 8 1 4 2 5 8 Меняет местами, так как 5 > 2 1 4 2 5 8  1 4 2 5 8 Теперь, ввиду того, что элементы стоят на своих местах (8 > 5), алгоритм не меняет их местами.

Второй проход:

 До После Описание шага 1 4 2 5 8 1 4 2 5 8  1 4 2 5 8 1 2 4 5 8 Меняет местами, так как 4 > 2 1 2 4 5 8 1 2 4 5 8 1 2 4 5 8  1 2 4 5 8

Теперь массив полностью отсортирован, но неоптимизированный алгоритм проведет еще два прохода, на которых ничего не изменится, в отличие от алгоритма, использующего вторую оптимизацию, который сделает один проход и прекратит свою работу, так как не сделает за этот проход ни одного обмена.

 Модификации 

 Сортировка чет-нечет 
Сортировка чет-нечет (англ. odd-even sort)   модификация пузырьковой сортировки, основанная на сравнении элементов стоящих на четных и нечетных позициях независимо друг от друга. Сложность   O(n^2) .
Псевдокод указан ниже:
 function oddEvenSort(a):
   for i = 0 to n - 1 
     if i mod 2 == 0
       for j = 2 to n - 1 step 2
         if a[j] < a[j - 1]
           swap(a[j - 1], a[j])  
     else      
       for j = 1 to n - 1 step 2
         if a[j] < a[j - 1]
           swap(a[j - 1], a[j])

Преимущество этой сортировки  на нескольких процессорах она выполняется быстрее, так как четные и нечетные индексы сортируются параллельно.

 Сортировка расческой 
Сортировка расческой (англ. comb sort)   модификация пузырьковой сортировки, основанной на сравнении элементов на расстоянии.  Сложность    O(n^2) , но стремится к          O(n \log n) .  Является самой быстрой квадратичной сортировкой. Недостаток  она неустойчива. Псевдокод указан ниже:

 function combSort(a):
   k = 1.3
   jump = n
   bool swapped = true
   while jump > 1 and swapped
     if jump > 1
       jump /= k
     swapped = false
     for i = 0 to size - jump - 1
       if a[i + jump] < a[i]
         swap(a[i], a[i + jump])
         swapped = true
Пояснения: Изначально расстояние между сравниваемыми элементами равно  \frac{n}{k} , где  k = 1{.}3   оптимальное число для этого алгоритма. Сортируем массив по этому расстоянию, потом уменьшаем его по этому же правилу. Когда  расстояние между сравниваемыми элементами достигает единицы, массив досортировывается обычным пузырьком.

 Сортировка перемешиванием  
Сортировка перемешиванием (англ. cocktail sort), также известная как Шейкерная сортировка    разновидность пузырьковой сортировки, сортирующая массив в двух направлениях на каждой итерации. В среднем, сортировка перемешиванием работает в два раза быстрее пузырька. Сложность    O(n^2) , но стремится она к  O(k \cdot n) , где  k   максимальное расстояние элемента в неотсортированном массиве от его позиции в отсортированном массиве. Псевдокод указан ниже:

 function shakerSort(a):
   begin = -1
   end = n - 2
   while swapped
     swapped = false   
     begin++
     for i = begin to end 
       if a[i] > a[i + 1] 
         swap(a[i], a[i + 1])
         swapped = true    
     if !swapped
       break    
     swapped = false 
     end--
     for i = end downto begin
       if a[i] > a[i + 1] 
         swap(a[i], a[i + 1])
         swapped = true

 См. также 
 Сортировка выбором
 Сортировка вставками
 Сортировка кучей
 Сортировка слиянием
 Быстрая сортировка
 Сортировка подсчетом

 Источники информации 
 Сортировка пузырьком  Википедия
 Визуализатор
  Сортировка чет-нечет  Википедия
 Сортировка расческой  Википедия
 Сортировка перемешиванием  Википедия

Категория: Дискретная математика и алгоритмы
Категория: Сортировка
Категория: Квадратичные сортировки-----Сортировка вставками (англ. Insertion sort) — квадратичный алгоритм сортировки.

Алгоритм
Задача заключается в следующем: есть часть массива, которая уже отсортирована, и требуется вставить остальные элементы массива в отсортированную часть, сохранив при этом упорядоченность. Для этого на каждом шаге алгоритма мы выбираем один из элементов входных данных и вставляем его на нужную позицию в уже отсортированной части массива, до тех пор пока весь набор входных данных не будет отсортирован. Метод выбора очередного элемента из исходного массива произволен, однако обычно (и с целью получения устойчивого алгоритма сортировки), элементы вставляются по порядку их появления во входном массиве.

Так как в процессе работы алгоритма могут меняться местами только соседние элементы, каждый обмен уменьшает число инверсий на единицу. Следовательно, количество обменов равно количеству инверсий в исходном массиве вне зависимости от реализации сортировки. Максимальное количество инверсий содержится в массиве, элементы которого отсортированы по невозрастанию. Число инверсий в таком массиве \displaystyle \frac {n(n - 1)} {2}.

Алгоритм работает за O(n + k), где k — число обменов элементов входного массива, равное числу инверсий. В среднем и в худшем случае — за O(n^2). Минимальные оценки встречаются в случае уже упорядоченной исходной последовательности элементов, наихудшие — когда они расположены в обратном порядке.

Псевдокод
 function insertionSort(a):
   for i = 1 to n - 1
     j = i - 1
     while j   \geqslant  0 and a[j] > a[j + 1] 
       swap(a[j], a[j + 1])
       j--

Пример работы
Пример работы алгоритма для массива [ 5, 2, 4, 3, 1 ]

 До После Описание шагаПервый проход (проталкиваем второй элемент — 2) 5 2 4 3 1 2 5 4 3 1 Алгоритм сравнивает второй элемент с первым и меняет их местами.Второй проход (проталкиваем третий элемент — 4) 2 5 4 3 1  2 4 5 3 1 Сравнивает третий со вторым и меняет местами 2 4 5 3 1 2 4 5 3 1 Второй и первый отсортированы, swap не требуетсяТретий проход (проталкиваем четвертый — 3) 2 4 5 3 1 2 4 3 5 1 Меняет четвертый и третий местами 2 4 3 5 1 2 3 4 5 1 Меняет третий и второй местами 2 3 4 5 1 2 3 4 5 1 Второй и первый отсортированы, swap не требуетсяЧетвертый проход (проталкиваем пятый элемент — 1) 2 3 4 5 1 2 3 4 1 5 Меняет пятый и четвертый местами 2 3 4 1 5 2 3 1 4 5 Меняет четвертый и третий местами 2 3 1 4 5 2 1 3 4 5  Меняет третий и второй местами 2 1 3 4 5 1 2 3 4 5 Меняет второй и первый местами. Массив отсортирован.
 Оптимизации 
 Бинарные вставки 
Теперь вместо линейного поиска позиции мы будем использовать  бинарный поиск, следовательно количество сравнений изменится с O(N^2) до  O(N\log N) . Количество сравнений заметно уменьшилось, но для того, чтобы поставить элемент на своё место, всё ещё необходимо переместить большое количество элементов. В итоге время выполнения алгоритма в асимптотически не уменьшилось. Бинарные вставки выгодно использовать только в случае когда сравнение занимает много времени по сравнению со сдвигом. Например когда мы используем массив длинных чисел. 
 function insertionSort(a):
   for i = 1 to n - 1
     j = i - 1
     k = binSearch(a, a[i], 0, j)
     for m = j downto k
       swap(a[m], a[m+1])

 Двухпутевые вставки 
Суть этого метода в том, что вместо отсортированной части массива мы используем область вывода. Первый элемент помещается в середину области вывода, а место для последующих элементов освобождается путём сдвига элементов влево или вправо туда, куда выгоднее.
Пример для набора элементов [ 5, 7, 3, 4, 6 ]    
 До После Описание шагаПервый проход (проталкиваем первый элемент — 5)  5 Так как в поле вывода нет элементов, то мы просто добавляем элемент туда.Второй проход (проталкиваем второй элемент — 7) 5  5 7 С помощью Бинарного поиска находим позицию и, так как позиция крайняя, то сдвигать ничего не приходится.Третий проход (проталкиваем третий — 3) 5 7 3 5 7 С помощью Бинарного поиска находим позицию и, так как позиция крайняя, то сдвигать ничего не приходится.Четвертый проход (проталкиваем четвертый элемент — 4) 3 5 7 3 4 5 7 С помощью Бинарного поиска находим позицию. Расстояние до левого края зоны вывода меньше, чем до правого, значит сдвигаем левую часть.Четвертый проход (проталкиваем пятый элемент — 6) 3 4 5 7 3 4 5 6 7 Расстояние до правого края меньше чем до левого, следовательно двигаем правую часть.    
Как можно заметить структура поля вывода имеет сходство с  деком, а именно мы выбираем край к которому ближе наш элемент, затем добавляем с этой стороны наш элемент и двигаем его. Как мы видим в этом примере понадобилось сдвинуть всего 3 элемента. Благодаря тому что для вставки j-ого элемента потребуется j/2 сдвигов в худшем случае вместо j, то и итоговое число необходимых операций в худшем случае составит N^2 / 4 + N \log N.

 См. также 
 Сортировка пузырьком
 Сортировка выбором
 Сортировка кучей
 Сортировка слиянием
 Быстрая сортировка
 Сортировка подсчетом
 Сортировка Шелла
 Источники информации
 Сортировка вставками
 Н. Вирт Алгоритмы и структуры данных  Невский Диалект, 2008.  352 с.  ISBN 978-5-7940-0065-8
 Визуализатор квадратичных алгоритмов
 Презентация «Сортировка вектора - 3. Insertion Sort»
Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Квадратичные сортировки-----Сортировка кучей, пирамидальная сортировка (англ. Heapsort)  алгоритм сортировки, использующий структуру данных двоичная куча. Это неустойчивый алгоритм сортировки с временем работы O(n\log{n}) , где n  количество элементов для сортировки, и использующий O(1) дополнительной памяти.

 Алгоритм 
Необходимо отсортировать массив A, размером n. Построим на базе этого массива за O(n) кучу для максимума. Так как максимальный элемент находится в корне, то если поменять его местами с A[n - 1], он встанет на своё место. Далее вызовем процедуру  \mathrm{siftDown(0)} , предварительно уменьшив  \mathrm{heapSize}  на 1. Она за O(\log{n}) просеет A[0] на нужное место и сформирует новую кучу (так как мы уменьшили её размер, то куча располагается с A[0] по A[n - 2], а элемент A[n-1] находится на своём месте). Повторим эту процедуру для новой кучи, только корень будет менять местами не с A[n - 1], а с A[n-2]. Делая аналогичные действия, пока  \mathrm{heapSize}   не станет равен 1, мы будем ставить наибольшее из оставшихся чисел в конец не отсортированной части. Очевидно, что таким образом, мы получим отсортированный массив.

 Реализация 
\mathrm{A}  массив, который необходимо отсортировать
\mathrm{n}  количество элементов в нём
 \mathrm{buildHeap(A)}   процедура, которая строит из передаваемого массива кучу для максимума в этом же массиве
 \mathrm{siftDown(A, i, len)}   процедура, которая просеивает вниз элемент  \mathrm{A[i]}  в куче из  \mathrm{len}  элементов, находящихся в начале массива  \mathrm{A} 
  fun heapSort(A : list <T>):
    buildHeap(A)
    heapSize = A.size
    for i = 0 to n - 1
      swap(A[0], A[n - 1 - i])
      heapSize--
      siftDown(A, 0, heapSize)

 Сложность 
Операция  \mathrm{siftDown}  работает за O(\log{n}). Всего цикл выполняется (n - 1) раз. Таким образом сложность сортировки кучей является O(n\log{n}).

Достоинства:
 худшее время работы  O(n\log{n}),
 требует O(1) дополнительной памяти.
Недостатки:
 неустойчивая,
 на почти отсортированных данных работает столь же долго, как и на хаотических данных.

 Пример 

  155px|thumb|Строим кучу
 155px|thumb|Первый проход
 155px|thumb|Строим новую кучу
  155px|thumb|Второй проход
 155px|thumb|Третий проход
 155px|thumb|Четвёртый проход
 

Пусть дана последовательность из 5 элементов 3, 2, 4, 1, 5.

 Массив Описание шага 5 3 4 1 2 Строим кучу из исходного массива Первый проход 2 3 4 1 5 Меняем местами первый и последний элементы  4 3 2 1 5 Строим кучу из первых четырёх элементовВторой проход 1 3 2 4 5 Меняем местами первый и четвёртый элементы  3 1 2 4 5 Строим кучу из первых трёх элементовТретий проход 2 1 3 4 5 Меняем местами первый и третий элементы  2 1 3 4 5 Строим кучу из двух элементовЧетвёртый проход 1 2 3 4 5 Меняем местами первый и второй элементы   1 2 3 4 5 Массив отсортирован

 JSort 
JSort является модификацией сортировки кучей, которую придумал Джейсон Моррисон (Jason Morrison).
Алгоритм частично упорядочивает массив, строя на нём два раза кучу: один раз передвигая меньшие элементы влево, второй раз передвигая большие элементы вправо. Затем к массиву применяется
сортировка вставками, которая при почти отсортированных данных работает за O(n).

Достоинства:
В отличие от сортировки кучей, на почти отсортированных массивах работает быстрее, чем на случайных.
В силу использования сортировки вставками, которая просматривает элементы последовательно, использование кэша гораздо эффективнее.
Недостатки:
На длинных массивах, возникают плохо отсортированные последовательности в середине массива, что приводит к ухудшению работы сортировки вставками.
 
 Алгоритм 
Построим кучу для минимума на этом массиве. 
Тогда наименьший элемент окажется на первой позиции, а левая часть массива окажется почти отсортированной, так как ей будут соответствовать верхние узлы кучи.
Теперь построим на этом же массиве кучу так, чтобы немного упорядочить правую часть массива. Эта куча должна быть кучей для максимума и быть "зеркальной" к массиву, то есть чтобы её корень соответствовал последнему элементу массива.
К получившемуся массиву применим сортировку вставками.

 Сложность 

Построение кучи занимает O(n). Почти упорядоченный массив сортировка вставками может отсортировать  O(n), но в худшем случае за O(n^2).

Таким образом, наихудшая оценка Jsort  O(n^2).

 Пример 
Рассмотрим, массив  A  =  [1, 2, 8, 15, 17, 20, 31, 32, 30, 2, 3, 5, 10, 11, 24 ] 

Построим на этом массиве кучу для минимума:
 400px 
Массив выглядит следующим образом:
 400px 
Заметим, что начало почти упорядочено, что хорошо скажется на использовании сортировки вставками.

Построим теперь зеркальную кучу для максимума на этом же массиве.
 400px 
Массив будет выглядеть следующим образом:
 400px 
Теперь и конец массива выглядит упорядоченным, применим сортировку вставками и получим отсортированный массив.

 См. также 
 Сортировка слиянием
 Быстрая сортировка
 Теорема о нижней оценке для сортировки сравнениями

 Источники информации 
 Кормен Т., Лейзерсон Ч., Ривест Р., Штайн К. Алгоритмы: построение и анализ, 2-е издание. Издательский дом "Вильямс", 2005. ISBN 5-8459-0857-4
Wikipedia  Heapsort
 Wikipedia  JSort
Хабрахабр  Описание сортировки кучей и JSort
Википедия  Пирамидальная сортировка
Категория: Дискретная математика и алгоритмы
Категория: Сортировки-----Сортировка Шелла (англ. Shellsort) — алгоритм сортировки, являющийся усовершенствованным вариантом сортировки вставками. 

Алгоритм
Каждый проход в алгоритме характеризуется смещением h_i, таким, что сортируются элементы отстающие друг от друга на h_i позиций.
Шелл предлагал использовать h_t = N/2, h_{t-1} = h_t/2, \ldots , h_0 = 1. Возможны и другие смещения, но h_0 = 1 всегда.

 Начало.
 Шаг 0. i = t.
 Шаг 1. Разобьем массив на списки элементов, отстающих друг от друга на h_i. Таких списков будет h_i.
 Шаг 2. Отсортируем элементы каждого списка сортировкой вставками.
 Шаг 3. Объединим списки обратно в массив. Уменьшим i. Если i неотрицательно — вернемся к шагу 1
 Конец.

Пример
Возьмем массив A= \{ 56, 43, 12, 78, 42, 93, 16, 55 \}  и смещения предложенные Шеллом.
 До После Описание шага Шаг 1 i = t = 2 56, 43, 12, 78, 42, 93, 16, 55 \{ 56, 42 \}  \{ 43, 93 \}  \{ 12, 16 \}  \{ 78, 55 \}  Разбили массив на 4 списка. Шаг 2 \{ 56, 42 \}  \{ 43, 93 \}  \{ 12, 16 \}  \{ 78, 55 \}  \{ 42, 56 \}  \{ 43, 93 \}  \{ 12, 16 \}  \{ 55, 78 \}  Отсортировали элементы списков сортировкой вставками. Количество обменов 2. Шаг 3 \{ 42, 56 \}  \{ 43, 93 \}  \{ 12, 16 \}  \{ 55, 78 \}  42, 43, 12, 55, 56, 93, 16, 78 Объединили списки в массив. Уменьшаем i на 1. i \geqslant 0, перейдем к шагу 1. Шаг 1 i = 1 42, 43, 12, 55, 56, 93, 16, 78 \{ 42, 12, 56, 16 \}  \{ 43, 55, 93, 78 \}  Разбили массив на 2 списка. Шаг 2 \{ 42, 12, 56, 16 \}  \{ 43, 55, 93, 78 \}  \{ 12, 16, 42, 56 \}  \{ 43, 55, 78, 93 \}  Отсортировали элементы списков сортировкой вставками. Количество обменов 4. Шаг 3 \{ 12, 16, 42, 56 \}  \{ 43, 55, 78, 93 \}  12, 43, 16, 55, 42, 78, 56, 93 Объединили списки в массив. Уменьшаем i на 1. i \geqslant 0, перейдем к шагу 1. Шаг 1 i = 0 42, 43, 12, 55, 56, 93, 16, 78 \{ 42, 43, 12, 55, 56, 93, 16, 78 \}  Разбили массив на 1 список. Шаг 2 \{ 42, 43, 12, 55, 56, 93, 16, 78 \}  \{ 12, 16, 42, 43, 55, 56, 78, 93 \}  Отсортировали элементы списков сортировкой вставками. Количество обменов 7. Шаг 3 \{ 12, 16, 42, 43, 55, 56, 78, 93 \}  12, 16, 42, 43, 55, 56, 78, 93 Объединили списки в массив. Уменьшаем i на 1. i<0.
Анализ метода Шелла
Понятно, что сложность алгоритма зависит от оптимальности выбора набора h_i.
Массив, где для любого i верно  a_i \leqslant a_{i+h}, назовем h упорядоченным.

Следующая лемма является следствием теоремы выше.

Доказательство данных теоремы и леммы изложено в книге, предложенной к прочтению.

В первом приближении функция f(n,h) равна  (\sqrt{\pi}/8)n^{3/2}h^{1/2}. Следовательно D для двух проходов будет примерно пропорционально 2N^2/h+\sqrt{\pi N^3h}. Поэтому наилучшее значение h равно приблизительно \sqrt[3]{16N/ {\pi}} \approx 1.72\sqrt[3]{N}, при таком выборе h среднее время сортировки пропорционально N^{5/3}.

Таким образом, применяя метод Шелла и используя всего 2 прохода, можно сократить  время по сравнению с методом простых вставок с O(N^2) до O(N^{1.(6)}).

Используя приведенные выше формулы, порог N^{1.5} преодолеть невозможно, но если убрать ограничение  h_{s+1}\,\bmod\,h_s = 0 его можно преодолеть.

Важно, что эта теорема дает оценку времени выполнения алгоритма в худшем случае.

Дальнейшее улучшение было получено Волганом Праттом. Если все смещения при сортировке выбираются из множества чисел вида 2^p3^q, меньших N, то время выполнения алгоритма будет порядка O(N\log^2{N}).

 См. также 
 Сортировка выбором
 Сортировка вставками
 Быстрая сортировка

 Источники информации 
 Дональд Кнут — Искусство программирования, том 3. Сортировка и поиск = The Art of Computer Programming, vol.3. Sorting and Searching. — 2-е изд. — М.: «Вильямс», 2007. — 824 с. — ISBN 5-8459-0082-4
 Сортировка Шелла — Википедия

Категория: Дискретная математика и алгоритмы
Категория: Сортировка
Категория: Сортировка на сравнениях-----Быстрая сортировка (англ. quick sort, сортировка Хоара)  один из самых известных и широко используемых алгоритмов сортировки. Среднее время работы O(n\log{n}), что является асимптотически оптимальным временем работы для алгоритма, основанного на сравнении. Хотя время работы алгоритма для массива из n элементов в худшем случае может составить \Theta(n^2), на практике этот алгоритм является одним из самых быстрых.

Алгоритм
Быстрый метод сортировки функционирует по принципу "разделяй и властвуй". 
 Массив  a[l \ldots r] типа  T  разбивается на два (возможно пустых) подмассива  a[l \ldots q] и  a[q+1 \ldots r], таких, что каждый элемент  a[l \ldots q] меньше или равен  a[q], который в свою очередь, не превышает любой элемент подмассива  a[q+1 \ldots r]. Индекс  вычисляется  в ходе процедуры разбиения.
 Подмассивы  a[l \ldots q] и  a[q+1 \ldots r] сортируются с помощью рекурсивного вызова процедуры быстрой сортировки.
 Поскольку подмассивы сортируются на месте, для их объединения не требуются никакие действия: весь массив  a[l \ldots r] оказывается отсортированным.

Псевдокод
   void quicksort(a: T[n], int l, int r)
      if l < r
         int q = partition(a, l, r)
         quicksort(a, l, q)
         quicksort(a, q + 1, r)
Для сортировки всего массива необходимо выполнить процедуру \mathrm{quicksort(a, 0, length[a] - 1)}.

Разбиение массива
Основной шаг алгоритма сортировки  процедура \mathrm{partition}, которая переставляет элементы массива a[l \ldots r] типа  T  нужным образом.
Разбиение осуществляется с использованием следующей стратегии. Прежде всего, в качестве разделяющего элемента произвольно выбирается элемент 
 a[(l + r) / 2] . Далее начинается просмотр с левого конца массива, который продолжается до тех пор, пока не будет найден элемент, превосходящий по значению разделяющий элемент, затем выполняется просмотр, начиная с правого конца массива, который продолжается до тех пор, пока не отыскивается элемент, который по значению меньше разделяющего. Оба элемента, на которых просмотр был прерван, очевидно, находятся не на своих местах в разделенном массиве, и потому они меняются местами. Так продолжаем дальше, пока не убедимся в том, что слева от левого указателя не осталось ни одного элемента, который был бы больше по значению разделяющего, и ни одного элемента справа от правого указателя, которые были бы меньше по значению разделяющего элемента.

Переменная  v  сохраняет значение разделяющего элемента  a[(l + r) / 2] , a  i  и  j  представляет собой, соответственно, указатели левого и правого просмотра. Цикл разделения увеличивает значение  i  и уменьшает значение  j  на  1 , причем условие, что ни один элемент слева от  i  не больше  v  и ни один элемент справа от  j  не меньше   v , не нарушается. Как только значения указателей пересекаются, процедура разбиения завершается.

   int partition(a: T[n], int l, int r)
      T v = a[(l + r) / 2]
      int i = l
      int j = r
      while (i  \leqslant  j) 
         while (a[i] < v)
            i++
         while (a[j] > v)
            j--
         if (i  \geqslant  j) 
            break
         swap(a[i++], a[j--])
      return j

Асимптотика
Худшее время работы
Предположим, что мы разбиваем массив так, что одна часть содержит n - 1 элементов, а вторая  1. Поскольку процедура разбиения занимает время \Theta(n), для времени работы T(n) получаем соотношение:

T(n) = T(n - 1) + \Theta(n) = \sum\limits_{k=1}^{n} \Theta(k) = \Theta(\sum\limits_{k=1}^{n} k) = \Theta(n^2).

Мы видим, что при максимально несбалансированном разбиении время работы составляет \Theta(n^2). В частности, это происходит, если массив изначально отсортирован.

Способ построить массив с максимальным количеством сравнений при выборе среднего элемента в качестве опорного
В некоторых алгоритмах быстрой сортировки в качестве опорного выбирается элемент, который стоит в середине рассматриваемого массива. Рассмотрим массив, на котором быстрая сортировка с выбором среднего элемента в качестве опорного сделает \Theta(n^2) сравнений. Очевидно, что это будет достигаться при худшем случае (когда при каждом разбиении в одном массиве будет оказываться 1, а в другом  n - 1  элемент).

Заполним сначала массив a длины n элементами от 1 до  n , затем применим следующий алгоритм (нумерация с нуля):
 
   void antiQsort(a: T[n])
      for i = 0 to n - 1 
         swap(a[i], a[i / 2])
Тогда на каждом шаге в качестве среднего элемента будет ставиться самый крупный элемент.

При выполнении \mathrm{partition} делается \Theta(n) сравнений из-за того, что с помощью индексов i и j мы проходим в лучшем случае \Omega(n) элементов (если функция прекращает свою работу, как только индексы встречаются), в худшем случае O(2n) элементов (если оба индекса полностью проходят массив). При каждом изменении индекса делается сравнение, значит, процедура \mathrm{partition} делает \Theta(n) сравнений с точностью до константы.

Рассмотрим, какой элемент будет выбираться опорным на каждом шаге. \mathrm{antiQsort} на каждом шаге меняет местами последний и центральный элементы, поэтому в центре оказывается самый крупный элемент. А \mathrm{partition} делает абсолютно симметричные этой процедуре операции, но в другую сторону: меняет местами центральный элемент с последним, так что самый крупный элемент становится последним, а затем выполняет на массиве длины на один меньшей ту же операцию. Получается, что опорным всегда будет выбираться самый крупный элемент, так как  \mathrm{antiQsort}  на массиве любой длины будет выполнять операции, обратные \mathrm{partition}. Фактически, \mathrm{partition}  это \mathrm{antiQsort}, запущенная в другую сторону. Также стоит отметить, что процедура разбиения будет делать на каждом шаге только одну смену элементов местами. Сначала i дойдет до середины массива, до опорного элемента, j останется равным индексу последнего элемента. Затем произойдет \mathrm{swap} и i снова начнет увеличиваться, пока не дойдет до последнего элемента, j опять не изменит свою позицию. Потом произойдет выход из \mathrm{while}.

Разбиение массива будет произведено \Theta(n) раз, потому что разбиение производится на массивы длины 1 и  n - 1  из-за того, что на каждом шаге разбиения в качестве опорного будет выбираться самый крупный элемент (оценка на худшее время работы доказана выше).  Следовательно, на массиве, который строится описанным выше способом, выполняется \Theta(n) \mathrm{partition} и \Theta(n) сравнений для каждого выполнения \mathrm{partition}. Тогда быстрая сортировка выполнит \Theta(n^2) сравнений для массива, построенного таким способом.

Способ построить массив с максимальным количеством сравнений при детерминированном выборе опорного элемента

Рассмотрим алгоритм построения массива, на котором быстрая сортировка с детерминированным выбором опорного элемента будет делать максимальное (в данном случае  \Theta(n^2)) количество сравнений. Такое число сравнений достигается при разбиении на массивы длиной 1 и n-1 на каждой итерации.  
Создадим массив a длины n, заполненный элементами типа pair. Такой элемент хранит пару значений (val, key), где val  элемент массива, а key  индекс. Изначально  a[i] элемент имеет вид (0, i).

Далее, запустим для данного массива алгоритм быстрой сортировки. Сравниваем два элемента типа pair по их значениям val. На каждом шаге будем выполнять следующие действия: при обращении к i-ому элементу в качестве опорного на шаге под номером k, присвоим val = n-k+1 для элемента a[i]. Затем выполним шаг сортировки. После завершения работы алгоритма быстрой сортировки, дополнительно отсортируем получившиеся элементы pair по значениям key. Искомым будет являться массив элементов val в соответствующей последовательности. 
 
Пример для n = 4, при последовательном выборе опорных элементов 2, 2, 1, 1.

 Построение массива Шаг 1.0  Шаг 1.1  Шаг 1.2  Шаг 2.0  Шаг 2.1  Шаг 2.2  Шаг 3.01 2 3 4  0 0 0 01 2 3 4  0 4 0 01 4 3 2  0 0 0 41 4 3 2  0 0 0 41 4 3 2  0 3 0 41 3 4 2  0 0 3 41 3 4 2  0 0 3 4 Шаг 3.1  Шаг 3.2  Шаг 4.0  Шаг 4.1  Шаг 4.2  Результат1 3 4 2  2 0 3 43 1 4 2  0 2 3 43 1 4 2  0 2 3 43 1 4 2  1 2 3 43 1 4 2  1 2 3 41 2 3 4  2 4 1 3 Итоговый массив2 4 1 3

Покажем, почему на данном массиве будет достигаться максимальное время работы быстрой сортировки. На этапе построения мы каждый раз присваивали опорному элементу максимальное значение. Следовательно, при выполнении \mathrm{quicksort} алгоритм в качестве опорного всегда будет выбирать наибольший элемент массива (выборка будет производится в том же порядке ввиду детерминированности определения опорного элемента). 
Таким образом, так как каждый раз массив разбивается на две части  большие или равные опорному элементы и меньшие его  на каждом шаге имеем разбиение на массивы длины 1 и n-1, чего мы, собственно, и добивались. При таком выполнении алгоритма происходит \Theta(n^2) разделений на два подмассива, и на каждом разделении выполняется \Theta(n^2) сравнений. 
Следовательно, на данном массиве быстрая сортировка работает за \Theta(n^2).

Среднее время работы

Mатожидание времени работы быстрой сортировки будет O(n \log n).

Модификации

Нерекурсивная реализация быстрой сортировки
Для выполнения быстрой сортировки можно воспользоваться  стеком, в котором в виде сортируемых подмассивов содержится перечень действий, которые предстоит выполнить. Каждый раз когда возникает необходимость в обработке подмассива, он выталкивается из стека. После разделения массива получаются два подмассива, требующих дальнейшей обработки, которые и заталкиваются в стек.
Представленная ниже нерекурсивная реализация использует стек, заменяя рекурсивные вызовы помещением в стек параметров функции, а вызовы процедур и выходы из них — циклом, который осуществляет выборку параметров из стека и их обработку, пока стек не пуст. Мы помещаем больший из двух подмассивов в стек первым с тем, чтобы максимальная глубина стека при сортировке N элементов не превосходила величины \log n. 
   void quicksort(a: T[n], int l, int r)
      stack< pair<int,int> > s   
      s.push(l, r)
      while (s.isNotEmpty)
         (l, r) = s.pop()
         if (r  \leqslant  l)
            continue
         int i = partition(a, l, r)
         if (i - l > r - i) 
            s.push(l, i - 1)
            s.push(i + 1, r)
         else
            s.push(i + 1, r)
            s.push(l, i - 1)

В качестве альтернативного варианта можно использовать обычную рекурсивную версию, в которой вместо того, чтобы после разделения массива вызывать рекурсивно процедуру разделения для обоих найденных подмассивов, рекурсивный вызов делается только для меньшего подмассива, а больший обрабатывается в цикле в пределах этого же вызова процедуры. С точки зрения эффективности в среднем случае разницы практически нет: накладные расходы на дополнительный рекурсивный вызов и на организацию сравнения длин подмассивов и цикла — примерно одного порядка. Зато глубина рекурсии ни при каких обстоятельствах не превысит \log n, а в худшем случае вырожденного разделения она вообще будет не более 1 — вся обработка пройдёт в цикле первого уровня рекурсии.

Улучшенная быстрая сортировка

Выбор медианы из первого, среднего и последнего элементов в качестве разделяющего элемента и отсечение рекурсии меньших подмассивов может 
привести к существенному повышению эффективности быстрой сортировки. Функция \mathrm{median} возвращает индекс элемента, являющегося медианой трех элементов. После этого он и средний элемент массива меняются местами, при этом медиана становится разделяющим элементом. Массивы небольшого размера (длиной  M = 11 и меньше) в процессе разделения игнорируются, затем для окончания сортировки используется  сортировка вставками. 

   const int M = 10
   void quicksort(a: T[n], int l, int r)
      if (r - l  \leqslant  M)
         insertion(a, l, r)
         return
      int med = median(a[l], a[(l + r) / 2], a[r])
      swap(a[med], a[(l + r) / 2])
      int i = partition(a, l, r)
      quicksort(a, l, i)
      quicksort(a, i + 1, r)

Вообще, можно применять любые эвристики по выбору опорного элемента. Например, в стандартной реализации в Java в качестве разделяющего выбирается средний из 7 элементов, равномерно распределённых по массиву.

Быстрая сортировка с разделением на три части

Когда в сортируемом массиве имеется множество повторяющихся ключей предыдущие реализации быстрой сортировки можно существенно улучшить. Например массив, который состоит из равных ключей, вовсе не нуждается в дальнейшей сортировке, однако предыдущие реализации продолжают процесс разделения, подвергая обработке все более мелкие подмассивы, независимо от того, насколько большим является исходный файл. 

В основу программы положено разделение массива на три части: 
на элементы,меньшие разделяющего элемента  a[l] \ldots a[i], 
элементы, равные разделяющему элементу a[i+1] \ldots a[j-1],
и элементы большие разделяющего элемента a[j] \ldots a[r]. 
После этого сортировка завершается двумя рекурсивными вызовами.

400px|thumb|center| Разделение массива  a 

Элементы массива равные разделяющему элементу находятся между  l  и  p  и между  q  и   r . В разделяющем цикле, когда указатели просмотра перестают изменяться и выполняется обмен значениями  i  и  j , каждый из этих элементов проверяется на предмет равенства разделяющему элементу. Если элемент, который сейчас находится слева, равен разделяющему элементу, то при помощи операции обмена он помещается в левую часть массива, если элемент, который сейчас находится справа, равен разделяющему элементу, то в результате операции обмена он помещается в правую часть массива. 
После того как указатели пересекутся, элементы, равные разделяющему элементу и находящиеся на разных концах массива, после операции обмена попадают в свои 
окончательные позиции. После этого указанные ключи могут быть исключены из подмассивов, для которых выполняются последующие рекурсивные вызовы. 

   void quicksort(a: T[n], int l, int r)
      T v = a[r]
      if (r  \leqslant  l)
         return
      int i = l
      int j = r - 1
      int p = l - 1
      int q = r
      while (i  \leqslant  j) 
         while (a[i] < v) 
            i++
         while (a[j] > v) 
            j--
         if (i  \geqslant  j)
            break
         swap(a[i], a[j])
         if (a[i] == v)
            p++
            swap(a[p], a[i])
         i++
         if (a[j] == v)
            q--
            swap(a[q], a[j])
         j--
      swap(a[i], a[r])
      j = i - 1
      i++
      for (int k = l; k  \leqslant  p; k++, j--) 
         swap(a[k], a[j])
      for (int k = r - 1; k  \geqslant  q; k--, i++) 
         swap(a[k], a[i]) 
      quicksort(a, l, j) 
      quicksort(a, i, r)

Параллельная сортировка

Еще одной оптимизацией является параллельная сортировка на основе быстрой. 
Пусть, исходный набор данных расположен на первом процессоре, с него начинается работа алгоритма. Затем исходный массив окажется разделенным на две части, меньшая из которых передастся другому свободному процессору, большая останется на исходном для дальнейшей обработки. Далее обе части опять будут разделены и опять на двух исходных останутся большие части, а меньшие отправятся другим процессорам. В этом заключается ускорение алгоритма. При задействовании всех процессоров, все части параллельно будут сортироваться последовательным алгоритмом.

Introsort

Для предотвращения ухудшения времени работы быстрой сортировки до O(n^2) при неудачных входных данных, также можно использовать алгоритм сортировки Introsort.
Он использует быструю сортировку и переключается на пирамидальную сортировку, когда глубина рекурсии превысит некоторый заранее установленный уровень (например, логарифм от числа сортируемых элементов). Так как после нескольких итераций быстрой сортировки с применением разных эвристик массив с большей вероятностью окажется «почти отсортированным», то пирамидальная сортировка может довольно быстро закончить дело. Также, пирамидальная сортировка хороша тем, что требует O(1) дополнительной памяти, в отличие от, например, сортировки слиянием, где потребуется O(n) дополнительной памяти.

См. также
 Сортировка Шелла
 Сортировка кучей
 Сортировка слиянием
 Timsort
 Smoothsort
 PSRS-сортировка

 Источники информации 
 Википедия  Быстрая сортировка
 Wikipedia  Quicksort
 Wikipedia  Introsort
 Т. Кормен, Ч. Лейзерсон, Р. Ривест: Алгоритмы: построение и анализ глава 7
 Р. Седжвик: Фундаментальные алгоритмы на С++ части 1 - 4

Категория: Дискретная математика и алгоритмы
Категория: Сортировка
Категория: Сортировки на сравнениях-----Сортировка слиянием (англ. Merge sort)  алгоритм сортировки, использующий O(n) дополнительной памяти и работающий за O(n\log(n)) времени.

Принцип работы
270px|right|thumb|Пример работы процедуры слияния.

300px|right|thumb|Пример работы рекурсивного алгоритма сортировки слиянием

300px|right|thumb|Пример работы итеративного алгоритма сортировки слиянием

Алгоритм использует принцип «разделяй и властвуй»: задача разбивается на подзадачи меньшего размера, которые решаются по отдельности, после чего их решения комбинируются для получения решения исходной задачи. Конкретно процедуру сортировки слиянием можно описать следующим образом:

 Если в рассматриваемом массиве один элемент, то он уже отсортирован  алгоритм завершает работу.
 Иначе массив разбивается на две части, которые сортируются рекурсивно.
 После сортировки двух частей массива к ним применяется процедура слияния, которая по двум отсортированным частям получает исходный отсортированный массив.

Слияние двух массивов
У нас есть два массива a и b (фактически это будут две части одного массива, но для удобства будем писать, что у нас просто два массива). Нам надо получить массив c размером |a| + |b|. Для этого можно применить процедуру слияния. Эта процедура заключается в том, что мы сравниваем элементы массивов (начиная с начала) и меньший из них записываем в финальный. И затем, в массиве у которого оказался меньший элемент, переходим к следующему элементу и сравниваем теперь его. В конце, если один из массивов закончился, мы просто дописываем в финальный другой массив. После мы наш финальный массив записываем заместо двух исходных и получаем отсортированный участок.

Множество отсортированных списков с операцией \mathrm{merge} является моноидом, где нейтральным элементом будет пустой список.

Ниже приведён псевдокод процедуры слияния, который сливает две части массива a  [left; mid) и [mid; right)
 function merge(a : int[n]; left, mid, right : int):
     it1 = 0
     it2 = 0
     result : int[right - left]
   
     while left + it1 < mid and mid + it2 < right
         if a[left + it1] < a[mid + it2]
             result[it1 + it2] = a[left + it1]
             it1 += 1
         else
             result[it1 + it2] = a[mid + it2]
             it2 += 1
   
     while left + it1 < mid
         result[it1 + it2] = a[left + it1]
         it1 += 1
   
     while mid + it2 < right
         result[it1 + it2] = a[mid + it2]
         it2 += 1
   
     for i = 0 to it1 + it2
         a[left + i] = result[i]

Рекурсивный алгоритм
Функция сортирует подотрезок массива с индексами в полуинтервале [left; right).
 function mergeSortRecursive(a : int[n]; left, right : int):
     if left + 1 >= right
         return
     mid = (left + right) / 2
     mergeSortRecursive(a, left, mid)
     mergeSortRecursive(a, mid, right)
     merge(a, left, mid, right)

Итеративный алгоритм
При итеративном алгоритме используется на O(\log n) меньше памяти, которая раньше тратилась на рекурсивные вызовы.
 function mergeSortIterative(a : int[n]):
     for i = 1 to n, i *= 2
         for j = 0 to n - i, j += 2 * i
             merge(a, j, j + i, min(j + 2 * i, n))

Время работы
Чтобы оценить время работы этого алгоритма, составим рекуррентное соотношение. Пускай T(n)  время сортировки массива длины n, тогда для сортировки слиянием справедливо T(n)=2T(n/2)+O(n) 
O(n)  время, необходимое на то, чтобы слить два массива длины n. Распишем это соотношение:

T(n)=2T(n/2)+O(n)=4T(n/4)+2O(n)=\dots=T(1)+\log(n)O(n)=O(n\log(n)).

Сравнение с другими алгоритмами
Достоинства:
 устойчивая,
 можно написать эффективную многопоточную сортировку слиянием,
 сортировка данных, расположенных на периферийных устройствах и не вмещающихся в оперативную памятьWikipedia  External sorting.
Недостатки:
 требуется дополнительно O(n) памяти, но можно модифицировать до O(1).

См. также
 Сортировка кучей
 Быстрая сортировка
 Timsort
 Cортировка слиянием с использованием O(1) дополнительной памяти

Примечания

Источники информации
Википедия  сортировка слиянием
Визуализатор
Викиучебник  Примеры реализации на различных языках программирования

Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Сортировки на сравнениях-----Сортировка сравнениями (англ. Comparison sort)  алгоритм  сортировки, который совершает операции сравнения элементов, но никак не использует их внутреннюю структуру.

Следствия

 См. также 
 Сортирующие_сети
 Быстрая_сортировка
 Двоичная_куча

Источники информации
 Кормен, Т., Лейзерсон, Ч., Ривест, Р., Штайн, К. Глава 8. Сортировка за линейное время // Алгоритмы: построение и анализ = Introduction to Algorithms / Под ред. И. В. Красикова. — 2-е изд. — М.: Вильямс, 2005. — 1296 с
 Андрей Калинин Сортировка за линейное время
 Конспект по курсу "Алгоритмы и алгоритмические языки" (доказательство теоремы через формулу Стирлинга).
 Лекториум "Алгоритмы сортировки"

Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Сортировки на сравнениях-----Сортировка подсчётом (англ. counting sort)  алгоритм сортировки целых чисел в диапазоне от 0 до некоторой константы k или сложных объектов, работающий за линейное время.
 Сортировка целых чисел 
Это простейший вариант алгоритма.
 Описание 
Исходная последовательность чисел длины n, а в конце отсортированная, хранится в массиве A. Также используется вспомогательный массив C с индексами от 0 до \mathrm k - 1, изначально заполняемый нулями.

 Последовательно пройдём по массиву A и запишем в C[i] количество чисел, равных i.

 Теперь достаточно пройти по массиву C и для каждого number \in \{0, ..., \mathrm k - 1\} в массив A последовательно записать число number\  C[number] раз.

 Псевдокод 
 function simpleCountingSort(A: int[n]): 
     for number = 0 to k - 1
         C[number] = 0 
     for i = 0 to n - 1
         C[A[i]] = C[A[i]] + 1;     
     pos = 0;
     for number = 0 to k - 1
         for i = 0 to C[number] - 1
             A[pos] = number;
             pos = pos + 1;

 Сортировка сложных объектов 
Сортировка целых чисел за линейное время это хорошо, но недостаточно. Иногда бывает очень желательно применить быстрый алгоритм сортировки подсчетом для упорядочивания набора каких-либо "сложных" данных. Под "сложными объектами" здесь подразумеваются структуры, содержащие в себе несколько полей. Одно из них мы выделим и назовем ключом, сортировка будет идти именно по нему (предполагается, что значения, принимаемые ключом  целые числа в диапазоне от 0 до \mathrm k-1).

Мы не сможем использовать здесь в точности тот же алгоритм, что и для сортировки подсчетом обычных целых чисел, потому что в наборе могут быть различные структуры, имеющие одинаковые ключи. Существует два способа справиться с этой проблемой  использовать списки для хранения структур в отсортированном массиве или заранее посчитать количество структур с одинаковыми ключами для каждого значения ключа.  

 Описание 
Исходная последовательность из n структур хранится в массиве A, а отсортированная  в массиве B того же размера. Кроме того, используется вспомогательный массив P с индексами от 0 до \mathrm k-1.

Идея алгоритма состоит в предварительном подсчете количества элементов с различными ключами в исходном массиве и разделении результирующего массива на части соответствующей длины (будем называть их блоками). Затем при повторном проходе исходного массива каждый его элемент копируется в специально отведенный его ключу блок, в первую свободную ячейку. Это осуществляется с помощью массива индексов P, в котором хранятся индексы начала блоков для различных ключей. P[key]  индекс в результирующем массиве, соответствующий первому элементу блока для ключа key. 

 Пройдем по исходному массиву A и запишем в P[i] количество структур, ключ которых равен i. 
Файл:Building_P.png

 Мысленно разобьем массив B на k блоков, длина каждого из которых равна соответственно P[0], P[1], ..., P[k].
Файл:Splitting_B_w_colors.png

 Теперь массив P нам больше не нужен. Превратим его в массив, хранящий в P[i] сумму элементов от 0 до i-1 старого массива P. 
Файл:P_after_adding.png

 Теперь "сдвинем" массив P на элемент вперед: в новом массиве P[0] = 0, а для i > 0 P[i] = P_{old}[i-1], где P_{old}  старый массив P.  Это можно сделать за один проход по массиву P, причем одновременно с предыдущим шагом.  После этого действия в массиве P будут хранится индексы массива B. P[key] указывает на начало блока в B, соответствующего ключу key.
Файл:P_as_array_of_pointers.png

 Произведем саму сортировку. Еще раз пройдем по исходному массиву A и для всех i \in [0, n-1] будем помещать структуру A[i] в массив B на место P[A[i].key], а затем увеличивать P[A[i].key] на 1. Здесь A[i].key  это ключ структуры, находящейся в массиве A на i-том месте. 
Файл:Sorting_A.png

Таким образом после завершения алгоритма в B будет содержаться исходная последовательность в отсортированном виде (так как блоки расположены по возрастанию соответствующих ключей).

Стоит также отметить, что эта сортировка является устойчивой, так как два элемента с одинаковыми ключами будут добавлены в том же порядке, в каком просматривались в исходном массиве A. Благодаря этому свойству существует цифровая сортировка.

 Псевдокод 
Здесь A и B  массивы структур размера n, с индексами от 0 до n-1.
P  целочисленный массив размера k, с индексами от 0 до k-1, где k  количество различных ключей.
 function complexCountingSort(A: int[n], B: int[n]):
     for i = 0 to k - 1
         P[i] = 0;         
     for i = 0 to length[A] - 1
         P[A[i].key] = P[A[i].key] + 1;     
     carry = 0;
     for i = 0 to k - 1
         temporary = P[i];
         P[i] = carry;
         carry = carry + temporary;     
     for i = 0 to length[A] - 1
         B[P[A[i].key]] = A[i];
         P[A[i].key] = P[A[i].key] + 1;
Здесь шаги 3 и 4 из описания объединены в один цикл.
Обратите внимание, что в последнем цикле инструкцией
 B[P[A[i].key]] = A[i];
копируется структура A[i] целиком, а не только её ключ.

 Анализ 
В первом алгоритме первые два цикла работают за \Theta(k) и \Theta(n), соответственно; двойной цикл за \Theta(n + k). Алгоритм имеет линейную временную трудоёмкость \Theta(n + k). Используемая дополнительная память равна \Theta(k).

Второй алгоритм состоит из двух проходов по массиву A размера n и одного прохода по массиву P размера k.
Его трудоемкость, таким образом, равна \Theta(n + k). На практике сортировку подсчетом имеет смысл применять, если k = O(n), поэтому можно считать время работы алгоритма равным \Theta(n). 
Как и в обычной сортировке подсчетом, требуется \Theta(n + k) дополнительной памяти  на хранение массива B размера n и массива P размера k.

Алгоритм работает за линейное время, но является псевдополиномиальным.

 Поиск диапазона ключей 
Если диапазон значений не известен заранее, то его можно найти с помощью линейного поиска минимума и максимума в исходном массиве, что не повлияет на асимптотику алгоритма. 
Нужно учитывать, что минимум может быть отрицательным, в то время как в массиве P индексы от 0 до k-1. Поэтому при работе с массивом P из исходного A[i]  необходимо вычитать минимум, а при обратной записи в B[i] прибавлять его.

 Источники информации 
 Сортировка подсчетом  Википедия
 Counting sort  Wikipedia
 Кормен Т., Лейзерсон Ч., Ривест Р. Алгоритмы: построение и анализ. — 2-е изд. — М.: Издательский дом «Вильямс», 2007. — С. 224226.

Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Другие сортировки-----Цифровая сортировка (англ. radix sort)  один из алгоритмов сортировки, использующих внутреннюю структуру сортируемых объектов.
 Алгоритм 
thumb|right|450px|Пример цифровой сортировки трехзначных чисел, начиная с младших разрядов
thumb|right|450px|Пример цифровой сортировки трехзначных чисел, начиная со старших разрядов
Имеем множество последовательностей одинаковой длины, состоящих из элементов, на которых задано отношение линейного порядка. Требуется отсортировать эти последовательности в лексикографическом порядке.

По аналогии с разрядами чисел будем называть элементы, из которых состоят сортируемые объекты, разрядами. Сам алгоритм состоит в последовательной сортировке объектов какой-либо устойчивой сортировкой по каждому разряду, в порядке от младшего разряда к старшему, после чего последовательности будут расположены в требуемом порядке.

Примерами объектов, которые удобно разбивать на разряды и сортировать по ним, являются числа и строки.

Для чисел уже существует понятие разряда, поэтому будем представлять числа как последовательности разрядов. Конечно, в разных системах счисления разряды одного и того же числа отличаются, поэтому перед сортировкой представим числа в удобной для нас системе счисления.

Строки представляют из себя последовательности символов, поэтому в качестве разрядов в данном случае выступают отдельные символы, сравнение которых обычно происходит по соответствующим им кодам из таблицы кодировок. Для такого разбиения самый младший разряд  последний символ строки.

Для вышеперечисленных объектов наиболее часто в качестве устойчивой сортировки применяют сортировку подсчетом.

Такой подход к алгоритму называют LSD-сортировкой (Least Significant Digit radix sort). Существует модификация алгоритма цифровой сортировки, анализирующая значения разрядов, начиная слева, с наиболее значащих разрядов. Данный алгоритм известен, как MSD-сортировка (Most Significant Digit radix sort).
 Корректность алгоритма LSD-сортировки 
Докажем, что данный алгоритм работает верно, используя метод математической индукции по номеру разряда. Пусть  n   количество разрядов в сортируемых объектах.

 База:  n = 1 . Очевидно, что алгоритм работает верно, потому что в таком случае мы просто сортируем младшие разряды какой-то заранее выбранной устойчивой сортировкой.

 Переход: Пусть для  n = k  алгоритм правильно отсортировал последовательности по  k  младшим разрядам. Покажем, что в таком случае, при сортировке по  (k + 1) -му разряду, последовательности также будут отсортированы в правильном порядке. 

Вспомогательная сортировка разобьет все объекты на группы, в которых  (k + 1) -й разряд объектов одинаковый. Рассмотрим такие группы. Для сортировки по отдельным разрядам мы используем устойчивую сортировку, следовательно порядок объектов с одинаковым  (k + 1) -м разрядом не изменился. Но по предположению индукции по предыдущим  k  разрядам последовательности были отсортированы правильно, и поэтому в каждой такой группе они будут отсортированы верно. Также верно, что сами группы находятся в правильном относительно друг друга порядке, а, следовательно, и все объекты отсортированы правильно по  (k + 1) -м младшим разрядам.

 Псевдокод 
 LSD-сортировка 
В качестве примера рассмотрим сортировку чисел. Как говорилось выше, в такой ситуации в качестве устойчивой сортировки применяют сортировку подсчетом, так как обычно количество различных значений разрядов не превосходит количества сортируемых элементов. Ниже приведен псевдокод цифровой сортировки, которой подается массив  A  размера  n   m -разрядных чисел . Сам по себе алгоритм представляет собой цикл по номеру разряда, на каждой итерации которого элементы массива  A  размещаются в нужном порядке во вспомогательном массиве  B . Для подсчета количества объектов,  i -й разряд которых одинаковый, а затем и для определения положения объектов в массиве  B  используется вспомогательный массив  C . Функция  \mathrm{digit(x, i)}  возвращает  i -й разряд числа  x . Также считаем, что значения разрядов меньше  k .
  function radixSort(int[] A):
      for i = 1 to m               
          for j = 0 to k - 1                              
              C[j] = 0                                  
          for j = 0 to n - 1
              d = digit(A[j], i)
              C[d]++
          count = 0
          for j = 0 to k - 1
              tmp = C[j]
              C[j] = count
              count += tmp
          for j = 0 to n - 1
              d = digit(A[j], i)                             
              B[C[d]] = A[j]            
              C[d]++
          A = B

 MSD-сортировка 
Будем считать, что у всех элементов одинаковое число разрядов. Если это не так, то положим на более старших разрядах элементы с самым маленьким значением — для чисел это 0. Сначала исходный массив делится на k частей, где k — основание, выбранное для представления сортируемых объектов. Эти части принято называть "корзинами" или "карманами". В первую корзину попадают элементы, у которых старший разряд с номером d = 0 имеет значение 0. Во вторую корзину попадают элементы, у которых старший разряд с номером d = 0 имеет значение 1 и так далее. Затем элементы, попавшие в разные корзины, подвергаются рекурсивному разделению по следующему разряду с номером d = 1. Рекурсивный процесс разделения продолжается, пока не будут перебраны все разряды сортируемых объектов и пока размер корзины больше единицы. То есть останавливаемся когда d > m или l \geqslant r, где m — максимальное число разрядов в сортируемых объектах, l, r — левая и правая границы отрезка массива A.

В основу распределения элементов по корзинам положен метод распределяющего подсчета элементов с одинаковыми значениями в сортируемом разряде. Для этого выполняется просмотр массива и подсчет количества элементов с различными значениями в сортируемом разряде. Эти счетчики фиксируются во вспомогательном массиве счетчиков cnt. Затем счетчики используются для вычисления размеров корзин и определения границ разделения массива. В соответствии с этими границами сортируемые объекты переносятся во вспомогательный массив c, в котором размещены корзины.
После того как корзины сформированы, содержимое вспомогательного массива c переносится обратно в исходный массив A и выполняется рекурсивное разделение новых частей по следующему разряду в пределах границ корзин, полученных на предыдущем шаге.

Изначально запускаем функцию так 

  function radixSort(int[] A, int l, int r, int d):
      if d > m or l >= r 
          return
      for j = 0 to k + 1 
          cnt[j] = 0
      for i = l to r                              
          j = digit(A[i], d)
          cnt[j + 1]++
      for j = 2 to k
          cnt[j] += cnt[j - 1]
      for i = l to r
          j = digit(A[i], d)
          c[l + cnt[j]] = A[i]
          cnt[j]--
      for i = l to r
          A[i] = c[i]
      radixSort(A, l, l + cnt[0] - 1, d + 1)
      for i = 1 to k
          radixSort(A, l + cnt[i - 1], l + cnt[i] - 1, d + 1)

Сложность
Сложность LSD-сортировки
Пусть  m   количество разрядов,  n   количество объектов, которые нужно отсортировать,  T(n)   время работы устойчивой сортировки. Цифровая сортировка выполняет  k  итераций, на каждой из которой выполняется устойчивая сортировка и не более  O(1)  других операций. Следовательно время работы цифровой сортировки   O(k T(n)) .

Рассмотрим отдельно случай сортировки чисел. Пусть в качестве аргумента сортировке передается массив, в котором содержатся  n   m -значных чисел, и каждая цифра может принимать значения от  0  до  k - 1 . Тогда цифровая сортировка позволяет отсортировать данный массив за время  O(m (n + k)) , если устойчивая сортировка имеет время работы  O(n + k) . Если  k  небольшое, то оптимально выбирать в качестве устойчивой сортировки сортировку подсчетом.

Если количество разрядов  константа, а  k = O(n) , то сложность цифровой сортировки составляет  O(n) , то есть она линейно зависит от количества сортируемых чисел.
Сложность MSD-сортировки
Пусть значения разрядов меньше b, а количество разрядов  k. При сортировке массива из одинаковых элементов MSD-сортировкой на каждом шаге все элементы будут находится в неубывающей по размеру корзине, а так как цикл идет по всем элементам массива, то получим, что время работы MSD-сортировки оценивается величиной O(nk), причем это время нельзя улучшить. Хорошим случаем для данной сортировки будет массив, при котором на каждом шаге каждая корзина будет делиться на b частей. Как только размер корзины станет равен 1, сортировка перестанет рекурсивно запускаться в этой корзине. Таким образом, асимптотика будет . Это хорошо тем, что не зависит от числа разрядов.

Существует также модификация MSD-сортировки, при которой рекурсивный процесс останавливается при небольших размерах текущего кармана, и вызывается более быстрая сортировка, основанная на сравнениях (например, сортировка вставками).

 См. также 
 Сортировка подсчетом
 Сортировка вставками

 Источники информации 
 Википедия  Цифровая сортировка
 Визуализатор 1 — Java-аплет.
 Визуализатор 2 — Java-аплет.
 Дональд Кнут Искусство программирования, том 3. Сортировка и поиск
 Кормен, Т., Лейзерсон, Ч., Ривест, Р., Штайн, К. Алгоритмы: построение и анализ

Категория: Дискретная математика и алгоритмы
Категория: Сортировки
Категория: Другие сортировки----- Модификация QuickSort 
 Описание алгоритма 

Будем использовать процедуру рассечения массива элементов из алгоритма сортировки QuickSort. Пусть нам надо найти k-ую порядковую статистику, а после рассечения опорный элемент встал на позицию m. Возможно три случая:

 k = m. Порядковая статистика найдена.
 k < m. Рекурсивно ищем k-ую статистику в первой части массива.
 k > m. Рекурсивно ищем (k - m - 1)-ую статистику во второй части массива.

 Код алгоритма 

Ниже представлен код представленного алгоритма. При реализации, однако, вместо рекурсивных вызовов изменяются границы поиска статистики во внешнем цикле. В коде считаем, что процедура partition принимает массив и границы отрезка, который будет рассечён (причём правая граница отрезка не включается), и возвращает индекс опорного элемента. Также считается, что массив индексируется с нуля.

 int findOrderStatistic(int[] array, int k) {
   int left = 0, right = array.length;
   while (true) {
     int mid = partition(array, left, right);
 
     if (mid == k) {
       return array[mid];
     }
     else if (k < mid) {
       right = mid;
     }
     else {
       left = mid + 1;
     }
   }
 }

 Анализ времени работы 

Аналогично QuickSort, может возникнуть такой же худший случай (процедура partition возвращает каждый раз левую или правую границу рассматриваемой части), при котором время работы составит \Omega(n^2). Однако, если считать, что partition возвращает все элементы рассматриваемого отрезка с равной вероятностью, то можно оценить матожидание времени работы как O(n).

Будем оценивать количество сравнений. При поиске статистики в массиве размера n функция partition (точнее, одна из распространённых вариаций) совершает не более n - 1 сравнений. Далее, в зависимости от k выбирается левая или правая половины (или вообще алгоритм завершает работу). Оценку проводим сверху, то есть, будем считать, что каждый раз выбирается большая половина.

T(n) \le \frac 1n \sum\limits_{k = 1}^n \left ( T \left ( \max \left \{k - 1; n - k \right \} \right ) + n - 1 \right ) =
= n - 1 + \frac 1n \sum\limits_{k = 1}^n T(\max \{k - 1; n - k\}) = n - 1 + \frac 2n \sum\limits_{k = \lfloor n/2 \rfloor}^{n - 1} T(k)

Предположим, что T(k) \le ck для некоторой константы c и всех k < n (будем доказывать оценку по индукции). Тогда верно неравенство:

T(n) = n - 1 + \frac 2n \sum\limits_{k = \lfloor n/2 \rfloor}^{n - 1} ck

Преобразуем сумму из правой части равенства по формуле суммы арифметической прогрессии и оценим преобразованное выражение:

\sum\limits_{k = \lfloor n/2 \rfloor}^{n - 1} ck = \frac 12 \left (\left \lceil \frac n2 \right \rceil - 1 \right) \left( c \left \lfloor \frac n2 \right \rfloor + c(n - 1) \right ) \le \frac c2 \left (\frac{n + 1}2 - 1\right) \frac{3n - 2}2 = c \frac{n - 1}4 \frac{3n - 2}2

Воспользуемся полученной оценкой для оценки исходного выражения. Также, предположим, что c \ge 4:

T(n) \le n - 1 + \frac{2c}n \frac{n - 1}4 \frac{3n - 2}2 = n - 1 + c\frac{n - 1}{2n} \frac{3n - 2}2 \le \frac c4 (n - 1) + \frac c4\left (\frac{n - 1}n (3n - 2)\right) \le
\le \frac c4 (n - 1 + 3n - 2) = \frac c4 (4n - 3) \le cn

Для довершения доказательства необходима проверка базы индукции, но она тривиальна: для выборки порядковой статистики из одного элемента сравнений не требуется: T(1) = 0 < 4. Итого, мы доказали, что T(n) \le 4n, следовательно, T(n) = O(n)

 Ссылки 
 Selection algorithm — Wikipedia
 Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Third Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Section 5.3.3: Minimum-Comparison Selection, pp.207–219.-----