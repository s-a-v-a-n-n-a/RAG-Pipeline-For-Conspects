{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наполнение базы данных.\n",
    "\n",
    "Данные для наполнения берутся с сайта [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0) от университета ИТМО. Скачиваемые данные очищаются от HTML-тегов, пишутся в текстовые файлы по темам, которые кладутся в директорию `text_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: requests in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.12.3)\n",
      "Collecting mwparserfromhell\n",
      "  Downloading mwparserfromhell-0.6.6-cp310-cp310-win_amd64.whl (100 kB)\n",
      "     ---------------------------------------- 0.0/100.5 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 30.7/100.5 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 100.5/100.5 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\savch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4) (2.6)\n",
      "Installing collected packages: mwparserfromhell\n",
      "Successfully installed mwparserfromhell-0.6.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\savch\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import mwparserfromhell\n",
    "\n",
    "def get_text(node,trim=False):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    res = node.find_all(\"div\", recursive=False)\n",
    "    if res:\n",
    "        if trim:\n",
    "            res = list(res)[1:-1]\n",
    "        return '\\n'.join(get_text(part) for part in res)\n",
    "    else:\n",
    "        return node.get_text()\n",
    "    \n",
    "def extract(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    art = soup.find(\"article\")\n",
    "    return get_text(html,True)\n",
    "\n",
    "def clean_wikitext(wikitext):\n",
    "    wikicode = mwparserfromhell.parse(wikitext)\n",
    "    text = wikicode.strip_code()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_titles = [\n",
    "    \"Хеш-таблица\",\n",
    "    \"Разрешение_коллизий\",\n",
    "    \"Хеширование_кукушки\",\n",
    "    \"Идеальное_хеширование\",\n",
    "    \"Перехеширование\",\n",
    "    \"Фильтр_Блума\",\n",
    "    \"Универсальное_семейство_хеш-функций\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://neerc.itmo.ru/wiki/api.php\"\n",
    "\n",
    "def get_web_content(title):\n",
    "    parameters = {\n",
    "       \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"rvprop\": \"content\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=parameters)\n",
    "    data = response.json()\n",
    "    pages = data['query']['pages']\n",
    "    for page_id, page_info in pages.items():\n",
    "        if page_id != \"-1\": \n",
    "            return page_info['revisions'][0]['*']\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(conspects, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as conspects_file:\n",
    "        for title in conspects:\n",
    "            conspects_file.write(conspects[title])\n",
    "            conspects_file.write('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(titles):\n",
    "    content = {\n",
    "        title: \"\" for title in titles\n",
    "    }\n",
    "    for title in titles:\n",
    "        content[title] = clean_wikitext(get_web_content(title))\n",
    "        print(content[title])\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Введение \n",
      "Существует два основных вида хеш-таблиц: с цепочками и открытой адресацией. Хеш-таблица содержит некоторый массив H, элементы которого есть пары (хеш-таблица с открытой адресацией) или списки пар (хеш-таблица с цепочками).\n",
      "\n",
      "Выполнение операции в хеш-таблице начинается с вычисления хеш-функции от ключа. Хеш-код i = h(key) играет роль индекса в массиве H, а зная индекс, мы можем выполнить требующуюся операцию (добавление, удаление или поиск).\n",
      "\n",
      "Количество коллизий зависит от хеш-функции; чем лучше используемая хеш-функция, тем меньше вероятность их возникновения. \n",
      "\n",
      "Способ разрешения коллизий — важная составляющая любой хеш-таблицы.\n",
      "\n",
      "Полностью избежать коллизий для произвольных данных невозможно в принципе, и хорошая хеш-функция в состоянии только минимизировать их количество. Но, в некоторых специальных случаях их удаётся избежать. Если все ключи элементов известны заранее, либо меняются очень редко, то можно подобрать хеш-функцию, с помощью которой, все ключи будут распределены по хеш-таблице без коллизий. Это хеш-таблицы с прямой адресацией; в них все операции, такие как: поиск, вставка и удаление работают за O(1).\n",
      "\n",
      "Если мы поделим число хранимых элементов на размер массива H (число возможных значений хеш-функции), то узнаем коэффициент заполнения хеш-таблицы (англ. load factor). От этого параметра зависит среднее время выполнения операций.\n",
      "\n",
      " Хеширование \n",
      "Хеширование (англ. hashing)  класс методов поиска, идея которого состоит в вычислении хеш-кода, однозначно определяемого элементом с помощью хеш-функции, и использовании его, как основы для поиска (индексирование в памяти по хеш-коду выполняется за O(1)). В общем случае, однозначного соответствия между исходными данными и хеш-кодом нет в силу того, что количество значений хеш-функций меньше, чем вариантов исходных данных, поэтому существуют элементы, имеющие одинаковые хеш-коды — так называемые коллизии, но если два элемента имеют разный хеш-код, то они гарантированно \n",
      "различаются. Вероятность возникновения коллизий играет немаловажную роль в оценке качества хеш-функций. Для того чтобы коллизии не замедляли работу с таблицей существуют методы для борьбы с ними.\n",
      "\n",
      " Виды хеширования \n",
      " По способу хранения:\n",
      "Статическое  фиксированное количество элементов. Один раз заполняем хеш-таблицу и осуществляем только проверку на наличие в ней нужных элементов,\n",
      "\n",
      "Динамическое  добавляем, удаляем и смотрим на наличие нужных элементов.\n",
      " По виду хеш-функции:\n",
      "Детерминированная хеш-функция,\n",
      "\n",
      "Случайная хеш-функция.\n",
      "\n",
      " Свойства хеш-таблицы \n",
      "\n",
      "На поиск элемента в хеш-таблице в худшем случае, может потребоваться столько же времени, как и в списке, а именно \\Theta(n), но на практике хеширование более эффективно. При некоторых разумных допущениях математическое ожидание времени поиска элемента в хеш-таблице составляет O(1). А все операции (поиск, вставка и удаление элементов) в среднем выполняются за время O(1).\n",
      "При этом не гарантируется, что время выполнения отдельной операции мало́, так как при достижении некоторого значения коэффициента заполнения необходимо перехешировать таблицу: увеличить размер массива H и заново добавить в новую хеш-таблицу все пары.\n",
      "\n",
      "Хеширование в современных языках программирования\n",
      "\n",
      "Почти во всех современных языках присутствуют классы, реализующие хеширование. Рассмотрим некоторые из них.\n",
      "Java\n",
      "HashMap  HashMap  Java Platform SE 7  реализация интерфейса ассоциативного массива с использованием хеш-таблицы,\n",
      "HashSet HashSet  Java Platform SE 7   реализация интерфейса множества с использованием хеш-таблицы,\n",
      "LinkedHashMap LinkedHashMap  Java Platform SE 7  потомок класса HashMap. Позволяет просматривать значения в том порядке, в котором они были добавлены.\n",
      "C++\n",
      "unordered_map unordered_map  cplusplus.com  реализация интерфейса ассоциативного массива с использованием хеш-таблицы,\n",
      "unordered_set  unordered_set  cplusplus.com   реализация интерфейса множества с использованием хеш-таблицы.\n",
      "Python (CPython)\n",
      "dict dictobject.c  https://github.com/python/cpython  реализация интерфейса ассоциативного массива с использованием хеш-таблицы,\n",
      "set setobject.c  https://hg.python.org    реализация интерфейса множества с использованием хеш-таблицы.\n",
      "\n",
      " Примечания \n",
      "\n",
      " Источники информации\n",
      " Томас Кормен, Чарльз Лейзерсон, Рональд Ривест, Клиффорд Штайн. «Алгоритмы. Построение и анализ»  «Вильямс», 2011 г.  1296 стр.  ISBN 978-5-8459-0857-5, 5-8459-0857-4, 0-07-013151-1\n",
      " Дональд Кнут. «Искусство программирования, том 3. Сортировка и поиск»  «Вильямс», 2007 г.  824 стр.  ISBN 0-201-89685-0\n",
      " Википедия  Хеш-таблица\n",
      "\n",
      "Категория:Дискретная математика и алгоритмы\n",
      "Категория:Хеширование\n",
      "Категория:Структуры данных\n",
      "Разрешение коллизий (англ. collision resolution) в хеш-таблице, задача, решаемая несколькими способами: метод цепочек, открытая адресация и т.д. Очень важно сводить количество коллизий к минимуму, так как это увеличивает время работы с хеш-таблицами. \n",
      "\n",
      " Разрешение коллизий с помощью цепочек \n",
      "thumb|380px|right|Разрешение коллизий при помощи цепочек.\n",
      "Каждая ячейка i массива H содержит указатель на начало списка всех элементов, хеш-код которых равен i, либо указывает на их отсутствие. Коллизии приводят к тому, что появляются списки размером больше одного элемента.\n",
      "\n",
      "В зависимости от того нужна ли нам уникальность значений операции вставки у нас будет работать за разное время. Если не важна, то мы используем список, время вставки в который будет в худшем случае равна O(1). Иначе мы проверяем есть ли в списке данный элемент, а потом в случае его отсутствия мы его добавляем. В таком случае вставка элемента в худшем случае будет выполнена за O(n)\n",
      "\n",
      "Время работы поиска в наихудшем случае пропорционально длине списка, а если все n ключей захешировались в одну и ту же ячейку (создав список длиной n) время поиска будет равно \\Theta(n) плюс время вычисления хеш-функции, что ничуть не лучше, чем использование связного списка для хранения всех n элементов.\n",
      "\n",
      "Удаления элемента может быть выполнено за O(1), как и вставка, при использовании двухсвязного списка.\n",
      "\n",
      " Линейное разрешение коллизий \n",
      "thumb|380px|right|Пример хеш-таблицы с открытой адресацией и линейным пробированием.\n",
      "Все элементы хранятся непосредственно в хеш-таблице, без использования связных списков. В отличие от хеширования с цепочками, при использовании этого метода может возникнуть ситуация, когда хеш-таблица окажется полностью заполненной, следовательно, будет невозможно добавлять в неё новые элементы. Так что при возникновении такой ситуации решением может быть динамическое увеличение размера хеш-таблицы, с одновременной её перестройкой.\n",
      "\n",
      " Стратегии поиска \n",
      "\n",
      " Последовательный поиск \n",
      "\n",
      "При попытке добавить элемент в занятую ячейку i начинаем последовательно просматривать ячейки i+1, i+2, i+3 и так далее, пока не найдём свободную ячейку. В неё и запишем элемент.\n",
      "\n",
      "400px|Последовательный поиск, частный случай линейного поиска.\n",
      "\n",
      " Линейный поиск \n",
      "\n",
      "Выбираем шаг q. При попытке добавить элемент в занятую ячейку i начинаем последовательно просматривать ячейки i+(1 \\cdot q), i+(2 \\cdot q), i+(3 \\cdot q) и так далее, пока не найдём свободную ячейку. В неё и запишем элемент.\n",
      "По сути последовательный поиск - частный случай линейного, где q=1.\n",
      "\n",
      "400px|Линейный поиск с шагом q.\n",
      "\n",
      " Квадратичный поиск \n",
      "\n",
      "Шаг q не фиксирован, а изменяется квадратично: q = 1,4,9,16.... Соответственно при попытке добавить элемент в занятую ячейку i начинаем последовательно просматривать ячейки  i+1, i+4, i+9 и так далее, пока не найдём свободную ячейку.\n",
      "\n",
      "400px|Квадратичный поиск.\n",
      "\n",
      " Проверка наличия элемента в таблице\n",
      "\n",
      "Проверка осуществляется аналогично добавлению: мы проверяем ячейку i и другие, в соответствии с выбранной стратегией, пока не найдём искомый элемент или свободную ячейку.\n",
      "\n",
      "При поиске элемента может получится так, что мы дойдём до конца таблицы. Обычно поиск продолжается, начиная с другого конца, пока мы не придём в ту ячейку, откуда начинался поиск.\n",
      "\n",
      " Проблемы данных стратегий \n",
      "\n",
      "Проблем две — крайне нетривиальное удаление элемента из таблицы и образование кластеров  — последовательностей занятых ячеек.\n",
      "\n",
      "Кластеризация замедляет все операции с хеш-таблицей: при добавлении требуется перебирать всё больше элементов, при проверке тоже. Чем больше в таблице элементов, тем больше в ней кластеры и тем выше вероятность того, что добавляемый элемент попадёт в кластер.\n",
      "Для защиты от кластеризации используется двойное хеширование и хеширование кукушки.\n",
      "\n",
      " Удаление элемента без пометок \n",
      "\n",
      "Рассуждение будет описывать случай с линейным поиском хеша. Будем при удалении элемента сдвигать всё последующие на q позиций назад. При этом:\n",
      " если в цепочке встречается элемент с другим хешем, то он должен остаться на своём месте (такая ситуация может возникнуть если оставшаяся часть цепочки была добавлена позже этого элемента)\n",
      " в цепочке не должно оставаться \"дырок\", тогда любой элемент с данным хешем будет доступен из начала цепи\n",
      "\n",
      "Учитывая это будем действовать следующим образом: при поиске следующего элемента цепочки будем пропускать все ячейки с другим значением хеша, первый найденный элемент копировать в текущую ячейку, и затем рекурсивно его удалять. Если такой следующей ячейки нет, то текущий элемент можно просто удалить, сторонние цепочки при этом не разрушатся (чего нельзя сказать про случай квадратичного поиска).\n",
      "\n",
      " Псевдокод \n",
      "\n",
      " function delete(Item i):\n",
      "      j = i + q\n",
      "      while table[j] == null or table[j].key != table[i].key\n",
      "         if table[j] == null\n",
      "            table[i] = null\n",
      "            return\n",
      "         j += q\n",
      "      table[i] = table[j]\n",
      "      delete(j)    \n",
      "\n",
      "Хеш-таблицу считаем зацикленной\n",
      "\n",
      "Вариант с зацикливанием мы не рассматриваем, поскольку если q взаимнопросто с размером хеш-таблицы, то для зацикливания в ней вообще не должно быть свободных позиций\n",
      "\n",
      "Теперь докажем почему этот алгоритм работает. Собственно нам требуется сохранение трёх условий.\n",
      " В редактируемой цепи не остаётся дырок\n",
      "Докажем по индукции. Если на данной итерации мы просто удаляем элемент (база), то после него ничего нет, всё верно. Если же нет, то вызванный в конце \\mathrm{delete} (см. псевдокод) заметёт созданную дыру (скопированный элемент), и сам, по предположению, новых не создаст.\n",
      " Элементы, которые уже на своих местах, не должны быть сдвинуты.\n",
      "Это учтено.\n",
      " В других цепочках не появятся дыры\n",
      "Противное возможно только в том случае, если какой-то элемент был действительно удалён. Удаляем мы только последнюю ячейку в цепи, и если бы на её месте возникла дыра для сторонней цепочки, это бы означало что элемент, стоящий на q позиций назад, одновременно принадлежал нашей и другой цепочкам, что невозможно.\n",
      "\n",
      "Двойное хеширование\n",
      "Двойное хеширование (англ. double hashing)  метод борьбы с коллизиями, возникающими при открытой адресации, основанный на использовании двух хеш-функций для построения различных последовательностей исследования хеш-таблицы.\n",
      "\n",
      "Принцип двойного хеширования\n",
      "При двойном хешировании используются две независимые хеш-функции  h_1(k)  и  h_2(k) . Пусть  k   это наш ключ,  m   размер нашей таблицы, n \\bmod m   остаток от деления  n  на  m , тогда сначала исследуется ячейка с адресом  h_1(k) , если она уже занята, то рассматривается  (h_1(k) +  h_2(k)) \\bmod m , затем  (h_1(k) +  2 \\cdot h_2(k)) \\bmod m  и так далее. В общем случае идёт проверка последовательности ячеек  (h_1(k) +  i \\cdot h_2(k)) \\bmod m  где   i = (0, 1, \\; ... \\;,  m - 1) \n",
      "\n",
      "Таким образом, операции вставки, удаления и поиска в лучшем случае выполняются за O(1), в худшем  за O(m), что не отличается от обычного линейного разрешения коллизий.\n",
      "Однако в среднем, при грамотном выборе хеш-функций, двойное хеширование будет выдавать лучшие результаты, за счёт того, что вероятность совпадения значений сразу двух независимых хеш-функций ниже, чем одной.\n",
      "\n",
      "\\forall x \\neq y \\; \\exists h_1,h_2 : p(h_1(x)=h_1(y))> p((h_1(x)=h_1(y)) \\land (h_2(x)=h_2(y)))\n",
      "\n",
      "Выбор хеш-функций\n",
      " h_1  может быть обычной хеш-функцией. Однако чтобы последовательность исследования могла охватить всю таблицу,  h_2  должна возвращать значения:\n",
      "не равные  0 \n",
      "независимые  от  h_1 \n",
      "взаимно простые с величиной хеш-таблицы\n",
      "\n",
      "Есть два удобных способа это сделать. Первый состоит в том, что в качестве размера таблицы используется простое число, а  h_2  возвращает натуральные числа, меньшие  m . Второй  размер таблицы является степенью двойки, а  h_2  возвращает нечетные значения.\n",
      "\n",
      "Например, если размер таблицы равен  m , то в качестве  h_2  можно использовать функцию вида  h_2(k) = k \\bmod (m-1) + 1 \n",
      "\n",
      "thumb|right|Вставка при двойном хешировании\n",
      "\n",
      "Пример\n",
      "\n",
      "Показана хеш-таблица размером 13 ячеек, в которой используются вспомогательные функции:\n",
      "\n",
      " h(k,i) = (h_1(k) + i \\cdot h_2(k)) \\bmod 13 \n",
      "\n",
      " h_1(k) = k \\bmod 13 \n",
      "\n",
      " h_2(k) = 1 + k \\bmod 11 \n",
      "\n",
      "Мы хотим вставить ключ 14. Изначально  i = 0 . Тогда  h(14,0) = (h_1(14) + 0\\cdot h_2(14)) \\bmod 13 = 1 . Но ячейка с индексом 1 занята, поэтому увеличиваем  i  на 1 и пересчитываем значение хеш-функции. Делаем так, пока не дойдем до пустой ячейки. При  i = 2  получаем  h(14,2) = (h_1(14) + 2\\cdot h_2(14)) \\bmod 13 = 9 . Ячейка с номером 9 свободна, значит записываем туда наш ключ.\n",
      "\n",
      "Таким образом, основная особенность двойного хеширования состоит в том, что при различных  k  пара  (h_1(k),h_2(k))  дает различные последовательности ячеек для исследования.\n",
      "\n",
      "Простая реализация\n",
      "Пусть у нас есть некоторый объект  item , в котором определено поле  key , от которого можно вычислить хеш-функции  h_1(key) и  h_2(key) \n",
      "\n",
      "Так же у нас есть таблица  table  величиной  m , состоящая из объектов типа  item .\n",
      "\n",
      "Вставка\n",
      " function add(Item item):\n",
      "      x = h1(item.key)\n",
      "      y = h2(item.key)\n",
      "      for (i = 0..m)    \t\n",
      "         if table[x] == null\n",
      "            table[x] = item\n",
      "            return      \n",
      "         x = (x + y) mod m   \n",
      "      table.resize()<span style=\"color:Green\">// ошибка, требуется увеличить размер таблицы\n",
      "\n",
      "Поиск\n",
      " Item search(Item key):\n",
      "      x = h1(key)\n",
      "      y = h2(key)\n",
      "      for (i = 0..m)\n",
      "         if table[x] != null\n",
      "            if table[x].key == key\n",
      "               return table[x]\n",
      "         else\n",
      "            return null\n",
      "         x = (x + y) mod m   \n",
      "      return null\n",
      "\n",
      "Реализация с удалением\n",
      "Чтобы наша хеш-таблица поддерживала удаление, требуется добавить массив deleted типов bool, равный по величине массиву table. Теперь при удалении мы просто будем помечать наш объект как удалённый, а при добавлении как не удалённый и замещать новым добавляемым объектом. При поиске, помимо равенства ключей, мы смотрим, удалён ли элемент, если да, то идём дальше.\n",
      "\n",
      "Вставка\n",
      " function add(Item item):\n",
      "      x = h1(item.key)\n",
      "      y = h2(item.key)\n",
      "      for (i = 0..m)   \t\n",
      "         if table[x] == null or deleted[x]\n",
      "            table[x] = item\n",
      "            deleted[x] = false\n",
      "            return      \n",
      "         x = (x + y) mod m   \n",
      "      table.resize()<span style=\"color:Green\">// ошибка, требуется увеличить размер таблицы\n",
      "Поиск\n",
      " Item search(Item key):\n",
      "      x = h1(key)\n",
      "      y = h2(key)\n",
      "      for (i = 0..m) \n",
      "         if table[x] != null\n",
      "            if table[x].key == key and !deleted[x]\n",
      "               return table[x]\n",
      "         else\n",
      "            return null\n",
      "         x = (x + y) mod m   \n",
      "      return null\n",
      "\n",
      "Удаление\n",
      " function remove(Item key):\n",
      "      x = h1(key)\n",
      "      y = h2(key)\n",
      "      for (i = 0..m)\n",
      "         if table[x] != null\n",
      "            if table[x].key == key\n",
      "               deleted[x] = true\n",
      "         else \n",
      "            return\n",
      "         x = (x + y) mod m\n",
      "\n",
      "Альтернативная реализация метода цепочек\n",
      "В Java 8 для разрешения коллизий используется модифицированный метод цепочек. Суть его заключается в том, что когда количество элементов в корзине превышает определенное значение, данная корзина переходит от использования связного списка к использованию сбалансированного дерева. Но данный метод имеет смысл лишь тогда, когда на элементах хеш-таблицы задан линейный порядок. То есть при использовании данныx типа \\mathbf{int} или \\mathbf{double} имеет смысл переходить к дереву поиска, а при использовании каких-нибудь ссылок на объекты не имеет, так как они не реализуют нужный интерфейс. Такой подход позволяет улучшить производительность с O(n) до O(\\log(n)). Данный способ используется в таких коллекциях как HashMap, LinkedHashMap и ConcurrentHashMap.\n",
      "\n",
      "500px|Хеширование в Java 8.\n",
      "\n",
      "См. также\n",
      " Хеширование\n",
      " Хеширование кукушки\n",
      " Идеальное хеширование\n",
      "\n",
      " Источники информации \n",
      " Бакнелл Дж. М. «Фундаментальные алгоритмы и структуры данных в Delphi», 2003\n",
      " Кормен, Томас Х., Лейзерсон, Чарльз И., Ривест, Рональд Л., Штайн Клиффорд «Алгоритмы: построение и анализ», 2-е издание. Пер. с англ. — М.:Издательский дом \"Вильямс\", 2010.— Парал. тит. англ. — ISBN 978-5-8459-0857-5 (рус.)\n",
      " Дональд Кнут. «Искусство программирования, том 3. Сортировка и поиск»  «Вильямс», 2007 г. ISBN 0-201-89685-0\n",
      " Седжвик Р. «Фундаментальные алгоритмы на C. Части 1-4. Анализ. Структуры данных. Сортировка. Поиск», 2003\n",
      " Handle Frequent HashMap Collisions with Balanced Trees\n",
      " Wikipedia  Double_hashing\n",
      " Разрешение коллизий\n",
      " Пример хеш таблицы\n",
      " Пример хеш таблицы с двойным хешированием\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Хеширование\n",
      "Категория: Структуры данных\n",
      "thumb|Пример хеширования кукушки. Стрелки показывают второе возможное место элементов. Если нам надо будет вставить новый элемент на место А, то мы поместим А в его вторую ячейку, занятую В, а В переместим в его вторую ячейку, которая сейчас свободна. А вот помещение нового элемента на место Н не получится: так как Н — часть цикла, добавленный элемент будет вытеснен после прохода по циклу.\n",
      "\n",
      "Хеширование кукушки(англ. Cuckoo hashing)  один из способов борьбы с коллизиями при создании хеш-таблицы.\n",
      "\n",
      "Алгоритм\n",
      "\n",
      "Основная идея хеширования кукушки — использование двух хеш-функций вместо одной (далее h_1(x) и h_2(x)). Также есть вариант алгоритма, в котором используются две хеш-таблицы, и первая хеш-функция указывает на ячейку из первой таблицы, а вторая — из второй. Рассмотрим алгоритмы функций add(x), remove(x) и contains(x).\n",
      "\n",
      "Выберем 2 хэш-функции h_1(x) и h_2(x) (из  универсального семейства хэш-функций).\n",
      "\n",
      "Add \n",
      "Добавляет элемент с ключом x в хэш-таблицу\n",
      "\n",
      " Если одна из ячеек с индексами h_1(x) или h_2(x) свободна, кладем в нее элемент. \n",
      " Иначе произвольно выбираем одну из этих ячеек, запоминаем элемент, который там находится, помещаем туда новый.\n",
      " Смотрим в ячейку, на которую указывает другая хеш-функция от элемента, который запомнили, если она свободна, помещаем его в нее. \n",
      " Иначе запоминаем элемент из этой ячейки, кладем туда старый. Проверяем, не зациклились ли мы.\n",
      " Если не зациклились, то продолжаем данную процедуру поиска свободного места пока не найдем свободное место или зациклимся.\n",
      " Иначе выбираем 2 новые хеш-функции и перехешируем все добавленные элементы.\n",
      " Также после добавления нужно увеличить размер таблицы в случае если она заполнена.\n",
      "\n",
      "Remove\n",
      "Удаляет элемент с ключом x из хэш-таблицы.\n",
      "\n",
      " Смотрим ячейки с индексами h_1(x) и h_2(x).\n",
      " Если в одной из них есть искомый элемент, просто помечаем эту ячейку как свободную.\n",
      "\n",
      "Contains\n",
      "Проверяет на наличие элемента x в хэш-таблице\n",
      "\n",
      " Смотрим ячейки с индексами h_1(x) и h_2(x).\n",
      " Если в одной из них есть искомый элемент, возвращаем true.\n",
      " Иначе возвращаем false.\n",
      "\n",
      " Зацикливание \n",
      "\n",
      "Зацикливание может возникнуть при добавлении элемента. Пусть мы добавляем элемент x. И обе ячейки h_1(x) и h_2(x) заняты. Элемент x положили изначально в ячейку h_i(x). Если в ходе перемещений элементов в таблице на очередном шаге мы опять хотим переместить элемент x в ячейку h_i(x), чтобы в ячейку h_j(x) ~(i \\ne j)  мы смогли поместить какой-то y (это может произойти, если в ходе перемещений элемент x был перемещен в ячейку h_j(x)), то произошло зацикливание.\n",
      "\n",
      "Например, зацикливание возникнет, если добавить в хэш-таблицу 3 элемента x,y,z у которых h_1(x)=h_1(y)=h_1(z)  и h_2(x)=h_2(y)=h_2(z) .\n",
      "\n",
      "Одним из способов решения проблемы зацикливания является смена хэш-функции, что было доказано Джоном Трампомhttps://eprint.iacr.org/2014/059.pdf\n",
      "\n",
      "Время работы алгоритма\n",
      "\n",
      "Удаление и проверка происходят за O(1) (что является основной особенностью данного типа хеширования), добавление в среднем происходит за O(1). Первые два утверждения очевидны: требуется проверить всего лишь 2 ячейки таблицы. \n",
      "\n",
      "Таким образом хеширование кукушки является одним из самых быстрых способов хеширования.\n",
      "\n",
      "Плюсы и минусы алгоритма\n",
      "\n",
      "Есть другие алгоритмы, которые используют несколько хеш-функций, в частности фильтр Блума, эффективная по памяти структура данных для нечётких множеств. Альтернативная структура данных для задач с теми же нечёткими множествами, основанная на кукушкином хешировании, называемая кукушкиным фильтром, использует даже меньшую память и (в отличие от классических фильтров Блума) позволяет удаление элемента, не только вставку и проверку существования. Однако теоретический анализ этих методов проведён существенно слабее, чем анализ фильтров БлумаBin Fan, Michael Kaminsky, David Andersen Cuckoo Filter: Better Than Bloom // ;login:. — USENIX, 2013. — Т. 38, вып. 4. — С. 36–40..\n",
      "\n",
      "Исследования, проведённые Жуковским, Хеманом и БонзомMarcin Zukowski, Sandor Heman, Peter Boncz Architecture-Conscious Hashing. — Proceedings of the International Workshop on Data Management on New Hardware (DaMoN), 2006., показали, что кукушкино хеширование существенно быстрее метода цепочек для малых хеш-таблиц, находящихся в кэше современных процессоров. Кеннет РоссKenneth Ross Efficient Hash Probes on Modern Processors. — IBM Research Report RC24100, 2006. показал блочную версию кукушкиного хеширования (блок содержит более одного ключа), который работает быстрее обычных методов для больших хеш-таблиц в случае высокого коэффициента загрузки. Скорость работы блочной версии кукушкиной хеш-таблицы позднее исследовал Аскитис по сравнению с другими схемами хэширования.\n",
      "\n",
      "Обзор МутцемахераM. Mitzenmacher. Proceedings of of the 17th Annual European Symposium on Algorithms (ESA). — 2009. представляет открытые проблемы, связанные с кукушкиным хешированием.\n",
      "\n",
      "Самый большой минуc  потраченная память. Чтобы гарантировать O(n) по времени, нужно чтобы пары ключ/значение занимали не более 50\\% памяти, потому что вытеснение старых элементов становится трудоемким. Также, добавление каждой новой хеш-функции значительно увеличивает среднюю скорость заполнения таблицы.\n",
      "\n",
      "См. также\n",
      " Хеш-таблица\n",
      " Разрешение коллизий\n",
      " Идеальное хеширование\n",
      "\n",
      "Примечания\n",
      "\n",
      "Источники информации\n",
      " Wikipedia — Cuckoo hashing\n",
      " Cuckoo hashing — Pagh, Rasmus; Rodler, Flemming Friche (2001) (PDF, PS)\n",
      "\n",
      " Примеры \n",
      " Concurrent high-performance Cuckoo hashtable written in C++\n",
      " Cuckoo hash map written in C++\n",
      " Static cuckoo hashtable generator for C/C++\n",
      " Generic Cuckoo hashmap in Java\n",
      " Cuckoo hash table written in Haskell\n",
      " Cuckoo hashing for Go\n",
      "\n",
      "Категория: Алгоритмы и структуры данных\n",
      "Категория: Хеширование\n",
      " Основная идея \n",
      "Идеальное хеширование используется в задачах со статическим множеством ключей (т.е. после того, как все ключи сохранены в таблице, их множество никогда не изменяется) для обеспечения хорошей асимптотики даже в худшем случае. При этом мы можем дополнительно хотеть, чтобы размер таблицы зависел от количества ключей линейно.\n",
      "\n",
      "В таком хешировании для доступа к данным потребуется лишь вычисление хеш-функций (одной или нескольких), что делает данный подход наибыстрейшим для доступа к статическим данным. Данная технология применяется в различных словарях и базах данных, в алгоритмах со статической (известной заранее) информацией.\n",
      "\n",
      "Будем использовать двухуровневую схему хеширования с универсальным хешированием на каждом уровне.\n",
      " Первый уровень \n",
      "Используется тот же принцип, что и в случае хеширования с цепочками: n ключей хешируются в m ячеек с использованием хеш-функции h(k) = ((a\\cdot k+b) \\bmod p) \\bmod m, случайно выбранной из  семейства универсальных хеш-функций H_{p,m}, где p — простое число, превышающее m.\n",
      "\n",
      " Второй уровень \n",
      "На данном уровне вместо создания списка ключей будем использовать вторичную хеш-таблицу S_j, хранящую все ключи, хешированные функцией h в ячейку j, со своей функцией h_j(k)=((a_j\\cdot k + b_j) \\bmod p) \\bmod m_j, выбранной из множества H_{p,m_j}. Путем точного выбора хеш-функции h_j мы можем гарантировать отсутствие коллизий на этом уровне. Для этого требуется, чтобы размер m_j хеш-таблицы S_j был равен квадрату числа n_j ключей, хешированных функцией h в ячейку j. \n",
      "\n",
      "Несмотря на квадратичную зависимость, ниже будет показано, что при корректном выборе хеш-функции первого уровня количество требуемой для хеш-таблицы памяти будет O(n).\n",
      "\n",
      " Теоретическое обоснование \n",
      "\n",
      "Это является очень хорошим результатом, если хотя бы вспомнить на примере  парадокса дней рождения о том, что вероятность коллизий растет крайне быстро по сравнению с размером хеш-таблицы.\n",
      "\n",
      "Теперь выведем 2 следствия из этой теоремы.\n",
      "\n",
      "См. также\n",
      " Хеширование\n",
      " Хеширование кукушки\n",
      " Разрешение коллизий\n",
      "\n",
      "Источники информации\n",
      " Т. Кормен. «Алгоритмы. Построение и анализ» второе издание, Глава 11.5, стр. 308\n",
      " Д.Э. Кнут. «Искусство программирования: Сортировка и поиск\" Том 3, Глава 6.4, стр. 563\n",
      " Wikipedia — Perfect hash function\n",
      " Universal and Perfect Hashing\n",
      " Универсальное хэширование. Идеальное хэширование\n",
      "\n",
      "Категория:Дискретная математика и алгоритмы \n",
      "Категория:Хеширование\n",
      "При добавлении в хеш-таблицу большого количества элементов могут возникнуть ухудшения в ее работе. Обработка любого вызова будет занимать больше времени из-за увеличения размеров цепочек при хешировании на списках или кластеризации при хешировании с открытой адресацией, также, при хешировании с открытой адресацией может произойти переполнение таблицы. Для избежания таких ситуаций используется выбор новой хеш-функции и (или) хеш-таблица большего размера. Этот процесс называется перехеширование (rehashing).\n",
      "\n",
      "Перехеширование при разных типах хеширования\n",
      "\n",
      "При хешировании цепочками\n",
      "\n",
      "При использовании хеширования цепочками , элементы с одинаковым результатом хеш-функции помещают в список. Так как операции \\mathrm{add(x)}, \\mathrm{contains(x)} и \\mathrm{remove(x)} работают за O(l), где l  длина списка, то с некоторого момента выгодно увеличить размер хеш-таблицы, чтобы поддерживать амортизационную стоимость операции O(1).\n",
      "\n",
      "Рассмотрим следующий алгоритм перехеширования: когда в хеш-таблицу добавлено \\frac{4n}{3} элементов, где n  размер хеш-таблицы, создадим новую хеш-таблицу размера 2n, и последовательно переместим в нее все элементы первой таблицы. При этом, сменим хеш-функцию так, чтобы она выдавала значения [0..2n-1].\n",
      "\n",
      "Найдем амортизационную стоимость добавления, после которого было сделано перехеширование, используя метод предоплаты. С момента последнего перехеширования было произведено не менее \\frac{2n}{3} операций \\mathrm{add(x)}, так как изначально в массиве находится \\frac{2n}{3} элементов (или 0 в начале работы), а перехеширование происходит при наличии \\frac{4n}{3} элементов. \n",
      "\n",
      "Для проведения перехеширования необходимо произвести \\frac{4n}{3} операций \\mathrm{add}(x), средняя стоимость которых составляет O(1) , потратить \\frac{4n}{3} операций на проход хеш-таблицы, и \\frac{4n}{3} операций на удаление предыдущей таблицы. В итоге, если мы увеличим стоимость каждой операции \\mathrm{add}(x) на 6, то есть на O(1), операция перехеширования будет полностью предоплачена. Значит, амортизационная стоимость перехеширования при открытом типе хеш-таблицы равна O(1).\n",
      "\n",
      "При хешировании с открытой адресацией\n",
      "При использовании хеширования цепочками , операции  \\mathrm{add}(x), \\mathrm{contains}(x) и \\mathrm{remove(x)} в худшем случае работают за O(k), где k  количество уже добавленных в таблицу элементов, поэтому перехеширование надо проводить при неполном заполнении хеш-таблицы.\n",
      "\n",
      "Будем проводить перехеширование при заполнении таблицы на \\frac{n}{2}, увеличивая размер таблицы в 2 раза. Аналогично случаю с открытым хешированием, для перехеширования необходимо будет потратить O(n) операций на обход таблицы, O(n)\\cdot A элементарных операций на добавление элементов, где A  стоимость операции \\mathrm{add(x)}, и O(n) операций на удаление таблицы. Так как A \\geqslant 1, и между последовательными перехешированиями производится O(n) добавлений, то можно предоплатить перехеширование, увеличив стоимость операции \\mathrm{add(x)} на O(1), и не изменив стоимость остальных операций.\n",
      "\n",
      "См. также\n",
      " Амортизационный анализ\n",
      " Хеширование\n",
      " Открытое и закрытое хеширование\n",
      "\n",
      "Источники информации\n",
      " Кормен, Томас Х., Лейзерсон, Чарльз И., Ривест, Рональд Л., Штайн Клиффорд «Алгоритмы: построение и анализ», 2-е издание. Пер. с англ. — М.:Издательский дом \"Вильямс\", 2010. — 1296 с.: ил. — Парал. тит. англ. — ISBN 978-5-8459-0857-5 (рус.)\n",
      " Дональд Кнут. «Искусство программирования, том 3. Сортировка и поиск»  «Вильямс», 2007 г. ISBN 0-201-89685-0\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы \n",
      "Категория: Амортизационный анализ\n",
      "Категория: Хеширование\n",
      "__TOC__\n",
      "\n",
      "Неформально вероятностное множество  это структура, позволяющая проверить принадлежность элемента множеству. Ответ может быть:\n",
      "\n",
      " элемент точно не принадлежит множеству,\n",
      " элемент возможно принадлежит множеству.\n",
      "Фильтр Блума (англ. Bloom filter) — это реализация вероятностного множества, придуманная Бёртоном Блумом в 1970 году, позволяющая компактно хранить элементы и проверять принадлежность заданного элемента к множеству. При этом существует возможность получить ложноположительное срабатывание (элемента в множестве нет, но структура данных сообщает, что он есть), но не ложноотрицательное.\n",
      "\n",
      "Фильтр Блума может использовать любой объём памяти, заранее заданный пользователем, причем чем он больше, тем меньше вероятность ложного срабатывания. Поддерживается операция добавления новых элементов в множество, но не удаления существующих (если только не используется модификация со счётчиками). С увеличением размера хранимого множества повышается вероятность ложного срабатывания.\n",
      "\n",
      " Описание структуры данных \n",
      "\n",
      "400px|thumb|Фильтр Блума с m = 9 и k = 3, хранящий множество из элементов A и B. Этот фильтр Блума может определить, что элемент C входит в множество, хотя он и не добавлен в него.\n",
      "\n",
      "Фильтр Блума представляет собой битовый массив из m бит и k различных хеш-функций h_1 \\dots h_k, равновероятно отображающих элементы исходного множества во множество  \\big\\{ 0, 1, \\dots m - 1 \\big\\}, соответствующее номерам битов в массиве. \n",
      "Изначально, когда структура данных хранит пустое множество, все m бит обнулены.\n",
      "\n",
      "Для добавления элемента  e  необходимо записать единицы на каждую из позиций h_1(e) \\dots h_k(e) битового массива.\n",
      "\n",
      "Чтобы проверить, что элемент e принадлежит множеству хранимых элементов, необходимо проверить состояние битов  h_1(e) \\dots h_k(e) . Если хотя бы один из них равен нулю, элемент не принадлежит множеству. Если все они равны единице, то структура данных сообщает, что элемент принадлежит множеству. При этом может возникнуть две ситуации: либо элемент действительно принадлежит к множеству, либо все эти биты оказались установлены при добавлении других элементов, что и является источником ложных срабатываний в этой структуре данных.\n",
      "\n",
      "По сравнению с хеш-таблицами, фильтр Блума может обходиться на несколько порядков меньшими объёмами памяти, жертвуя детерминизмом. Обычно он используется для уменьшения числа запросов к несуществующим данным в структуре данных с более дорогостоящим доступом (например, расположенной на жестком диске или в сетевой базе данных), то есть для «фильтрации» запросов к ней.\n",
      "\n",
      " Минимизация вероятности ложноположительного срабатывания \n",
      "\n",
      "Пусть размер битового массива  m , и заданы  k  хеш-функций, причем все хеш-функции выбираются случайным образом. Тогда вероятность, что в  j -ый бит не будет записана единица  i -ой хеш-функцией при вставке очередного элемента, равна:\n",
      "\n",
      "p(h_i(x) \\neq j) = 1 - \\dfrac {1}{m} \n",
      "\n",
      "Так как для упрощения анализа мы предполагаем, что значения хеш-функций являются независимыми в совокупности случайными величинами, то вероятность, что  j -ый бит останется нулевым после добавления очередного элемента, равна:\n",
      "\n",
      "p(h_i(x) \\neq j для  \\forall i \\in \\big\\{ 1 \\dots k \\big\\}) = (1 - \\dfrac {1}{m})^k \n",
      "\n",
      "А вероятность того, что  j -ый бит будет равен нулю после вставки  n  различных элементов в изначально пустой фильтр:\n",
      "\n",
      "(1 - \\dfrac {1}{m})^{kn} \n",
      "\n",
      "В силу второго замечательного предела и достаточно большого  m  можем это записать как:\n",
      "\n",
      "(1 - \\dfrac {1}{m})^{kn} \\approx e^{-kn/m}\n",
      "\n",
      "Ложноположительное срабатывание происходит тогда, когда для несуществующего элемента все  k  бит окажутся ненулевыми, и фильтр Блума ответит, что он входит в число вставленных элементов.\n",
      "Тогда вероятность такого события равна:\n",
      "\n",
      "(1 - e^{-kn/m})^k\n",
      "\n",
      "Для фиксированных  m  и  n , оптимальное число хеш-функций  k , минимизирующих вероятность ложноположительного срабатывания, равно:\n",
      "\n",
      "k = \\ln 2 \\dfrac {m}{n} \\approx 0.6931 \\dfrac {m}{n}\n",
      "\n",
      " Свойства \n",
      "\n",
      "Фильтр Блума может хранить универсальное множество всех возможных элементов. При этом все ячейки битового массива будут содержать  1 .\n",
      "\n",
      "При существовании двух фильтров Блума одинаковых размеров и с одинаковыми наборами хеш-функций, их объединение и пересечение может быть реализовано с помощью побитовых операций   \\vee   и \\wedge  .\n",
      "\n",
      " Примеры реализации фильтра Блума \n",
      "В ответ на запрос поиска есть вероятность получить положительный ответ, даже если этого элемента в данном множестве нет. Но если же ответ фильтра был отрицательным, запрашиваемого элемента точно нет. Чем больше размер этого множества, тем меньше вероятность получить некорректный ответ на запрос о наличии какого-либо элемента.\n",
      "\n",
      "Google BigTableGoogle BigTable использует фильтры Блума, пример вероятностного множества, для уменьшения числа обращений к жесткому диску при проверке на существование заданной строки или столбца в таблице базы данных. Такой подход к нахождению необходимого элемента в базе данных значительно ускоряет сам процесс поиска и уменьшает количество обращений к жесткому диску,\n",
      "компьютерные программы для проверки орфографии,\n",
      "BitcoinWikipedia  Bitcoin использует фильтр Блума, чтобы ускорить синхронизацию с кошельком.\n",
      "\n",
      " Примечания \n",
      "\n",
      " Источники информации\n",
      " Википедия  Фильтр Блума\n",
      " Wikipedia  Bloom filter\n",
      "Demetrescu, Camil. «Experimental Algorithms»  «Springer», 2007 г.  108-121 стр.  ISBN 978-3-540-72844-3\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы \n",
      "Категория: Хеширование\n",
      "Определение\n",
      "\n",
      "Качественная хеш-функция (англ. hash function) удовлетворяет (приближенно) условию простого равномерного хеширования: для каждого ключа, независимо от хеширования других ключей, равновероятно помещение его в любую из  m  ячеек. Но это условие обычно невозможно проверить, так как распределение вероятностей, с которыми поступают входные данные, как правило, неизвестно. К тому же, вставляемые ключи могут и не быть независимыми. Если наш противник будет умышленно выбирать ключи для хеширования при помощи конкретной хеш-функции, то при некоторых реализациях хеш-таблиц может получиться так, что все ключи будут записаны в одну и ту же ячейку таблицы, что приведет к среднему времени выборки  \\Theta(n) . Таким образом,  любая фиксированная хеш-функция становится уязвимой. И единственный эффективный выход из данной ситуации  случайный выбор хеш-функции. Такой подход называется универсальным хешированием. Он гарантирует хорошую производительность в среднем, вне зависимости от данных, выбранных нашим противником.\n",
      "\n",
      "Иными словами, при случайном выборе хеш-функции из  H  вероятность коллизии между различными ключами  k, l  не превышает вероятности совпадения двух случайным образом выбранных хеш-значений из множества  \\{0, 1, 2, .. , m - 1\\} , которая равна  \\frac{1}{m} .\n",
      "\n",
      "Построение универсального множества хеш-функций\n",
      "\n",
      " Попарная независимость \n",
      "\n",
      "Построение попарно независимого множества хеш-функций\n",
      "\n",
      "Источники информации\n",
      "\n",
      " Томас Х. Кормен, Чарльз И. Лейзерсон, Рональд Л. Ривест, Клиффорд Штайн Алгоритмы: построение и анализ — 2-е изд. — М.: «Вильямс», 2005. — с. 294. — ISBN 5-8459-0857-4\n",
      "\n",
      "Категория: Дискретная математика и алгоритмыКатегория:Хеширование\n"
     ]
    }
   ],
   "source": [
    "content = get_content(hash_titles)\n",
    "write_to_file(content, \"text_db/hashing.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorting_titles = [\n",
    "    \"Сортировка_выбором\",\n",
    "    \"Сортировка_пузырьком\",\n",
    "    \"Сортировка_вставками\",\n",
    "    \"Сортировка_кучей\",\n",
    "    \"Сортировка_Шелла\",\n",
    "    \"Быстрая_сортировка\",\n",
    "    \"Сортировка_слиянием\",\n",
    "    \"Теорема_о_нижней_оценке_для_сортировки_сравнениями\",\n",
    "    \"Сортировка_подсчётом\",\n",
    "    \"Цифровая_сортировка\",\n",
    "    \"Поиск_k-ой_порядковой_статистики\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сортировка выбором (англ. selection sort)  простой алгоритм сортировки со сложностью O(n^2), где n  количество элементов для сортировки.\n",
      "\n",
      " Алгоритм \n",
      "На каждом i-ом шаге алгоритма находим i-ый минимальный элемент и меняем его местами с i-ым элементом в массиве. Таким образом будет получен массив, отсортированный по неубыванию.\n",
      "\n",
      " Псевдокод \n",
      "Вариант 1.\n",
      "Будем каждый раз проходить по всем еще не отсортированным элементам, и, как только найдем элемент меньше, чем первый из неотсортированных, поменяем их местами. Таким образом будет нужно O(n^2) обменов (для каждого i требуется O(n-i) обменов). \n",
      "  function selectionSort(T[n] a):\n",
      "    for i = 0 to n - 2\n",
      "      for j = i + 1 to n - 1\n",
      "        if a[i] > a[j]\n",
      "          swap(a[i], a[j])\n",
      "\n",
      "Вариант 2.\n",
      "Второй вариант немного более экономный. Здесь мы будем менять местами элементы только 1 раз для каждого i, всего будет нужно O(n) обменов. Для этого сначала мы будем проходить по всем еще не отсортированным элементам, искать минимальный, и только потом менять местами минимальный и первый из неотсортированных.\n",
      "\n",
      " function selectionSort(T[n] a):\n",
      "    for i = 0 to n - 2\n",
      "      min = i\n",
      "      for j = i + 1 to n - 1\n",
      "        if a[j] < a[min]\n",
      "          min = j\n",
      "      swap(a[i], a[min])\n",
      "\n",
      " Пример \n",
      "\n",
      "Пусть дана последовательность из 5 элементов 5, 4, 1, 2, 3. Будем выделять текущий элемент на каждом шаге фиолетовым цветом, а минимальный черным жирным.\n",
      "\n",
      " Массив Описание шагаПервый проход (текущий массив начинается с первого элемента) 5 4 1 2 3 Находим первый минимальный элемент  1  1 4 5 2 3 Меняем минимальный и первый элементы местамиВторой проход (текущий массив начинается со следующего элемента) 1 4 5 2 3 Находим следующий минимальный элемент  2  1 2 5 4 3 Меняем минимальный и второй элементы местамиТретий проход (текущий массив начинается со следующего элемента) 1 2 5 4 3 Находим следующий минимальный элемент  3  1 2 3 4 5 Меняем минимальный и третий элементы местамиЧетвертый проход (текущий массив начинается со следующего элемента) 1 2 3 4 5 Находим следующий минимальный элемент  4. Меняем его местами с самим собой. 1 2 3 4 5 Массив отсортирован\n",
      "\n",
      " См. также \n",
      " Сортировка пузырьком\n",
      " Сортировка вставками\n",
      " Сортировка кучей\n",
      " Сортировка слиянием\n",
      " Быстрая сортировка\n",
      " Сортировка подсчетом\n",
      " Сортировка Шелла\n",
      "\n",
      " Источники информации  \n",
      "Википедия  Сортировка выбором\n",
      "Кормен Т., Лейзерсон Ч., Ривест Р., Штайн К. Алгоритмы: построение и анализ, 2-е издание. М.: Издательский дом \"Вильямс\", 2005. ISBN 5-8459-0857-4\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Квадратичные сортировки\n",
      "Сортировка простыми обменами, сортировка пузырьком (англ. bubble sort) — один из квадратичных алгоритмов сортировки.\n",
      "\n",
      " Алгоритм \n",
      "Алгоритм состоит в повторяющихся проходах по сортируемому массиву. На каждой итерации последовательно сравниваются соседние элементы, и, если порядок в паре неверный, то элементы меняют местами. За каждый проход по массиву как минимум один элемент встает на свое место, поэтому необходимо совершить не более  n - 1  проходов, где  n  размер массива, чтобы отсортировать массив.\n",
      "\n",
      "Ниже приведен псевдокод сортировки пузырьком, на вход которой подается массив  a[0..n - 1] .\n",
      " function bubbleSort(a):\n",
      "   for i = 0 to n - 2\n",
      "     for j = 0 to n - 2\n",
      "       if a[j] > a[j + 1]\n",
      "         swap(a[j], a[j + 1])\n",
      "\n",
      " Оптимизация \n",
      " Можно заметить, что после  i -ой итерации внешнего цикла  i  последних элементов уже находятся на своих местах в отсортированном порядке, поэтому нет необходимости производить их сравнения друг с другом. Следовательно, внутренний цикл можно выполнять не до  n - 2 , а до  n - i - 2 .\n",
      " Также заметим, что если после выполнения внутреннего цикла не произошло ни одного обмена, то массив уже отсортирован, и продолжать что-то делать бессмысленно. Поэтому внутренний цикл можно выполнять не  n - 1  раз, а до тех пор, пока во внутреннем цикле происходят обмены.\n",
      "\n",
      "При использовании первой оптимизации сортировка принимает следующий вид:\n",
      " function bubbleSort(a):\n",
      "   for i = 0 to n - 2\n",
      "     for j = 0 to n - i - 2\n",
      "       if a[j] > a[j + 1]\n",
      "         swap(a[j], a[j + 1])\n",
      "\n",
      "При использовании же обеих оптимизаций сортировка пузырьком выглядит так:\n",
      " function bubbleSort(a):\n",
      "   i = 0\n",
      "   t = true\n",
      "   while t\n",
      "     t = false\n",
      "     for j = 0 to n - i - 2\n",
      "       if a[j] > a[j + 1]\n",
      "         swap(a[j], a[j + 1])\n",
      "         t = true\n",
      "     i = i + 1\n",
      "\n",
      " Сложность \n",
      "В данной сортировке выполняются всего два различных вида операции: сравнение элементов и их обмен. Поэтому время всего алгоритма  T = T_1 + T_2 , где  T_1   время, затрачиваемое на сравнение элементов, а  T_2   время, за которое мы производим все необходимые обмены элементов.\n",
      "\n",
      "Так как в алгоритме меняться местами могут только соседние элементы, то каждый обмен уменьшает количество инверсий на единицу. Следовательно, количество обменов равно количеству инверсий в исходном массиве вне зависимости от реализации сортировки. Максимальное количество инверсий содержится в массиве, элементы которого отсортированы по убыванию. Несложно посчитать, что количество инверсий в таком массиве  \\frac {n (n - 1)} {2} . Получаем, что  T_2 = O(n^2) .\n",
      "\n",
      "В неоптимизированной реализации на каждой итерации внутреннего цикла производятся  n - 1  сравнений, а так как внутренний цикл запускается также  n - 1  раз, то за весь алгоритм сортировки производятся  (n - 1)^2  сравнений.\n",
      "\n",
      "В оптимизированной версии точное количество сравнений зависит от исходного массива. Известно, что худший случай равен  \\frac {n (n - 1)} {2} , а лучший   n-1 . Следовательно,  T_1 = O(n^2) .\n",
      "\n",
      "В итоге получаем  T = T_1 + T_2 = O(n^2) + O(n^2) = O(n^2) .\n",
      "\n",
      " Пример работы алгоритма \n",
      "\n",
      "Возьмём массив  [5, 1, 4, 2, 8]  и отсортируем значения по возрастанию, используя сортировку пузырьком. Выделены те элементы, которые сравниваются на данном этапе.\n",
      "\n",
      "Первый проход:\n",
      "\n",
      " До После Описание шага 5 1 4 2 8 1 5 4 2 8 Здесь алгоритм сравнивает два первых элемента и меняет их местами. 1 5 4 2 8  1 4 5 2 8 Меняет местами, так как 5 > 4 1 4 5 2 8 1 4 2 5 8 Меняет местами, так как 5 > 2 1 4 2 5 8  1 4 2 5 8 Теперь, ввиду того, что элементы стоят на своих местах (8 > 5), алгоритм не меняет их местами.\n",
      "\n",
      "Второй проход:\n",
      "\n",
      " До После Описание шага 1 4 2 5 8 1 4 2 5 8  1 4 2 5 8 1 2 4 5 8 Меняет местами, так как 4 > 2 1 2 4 5 8 1 2 4 5 8 1 2 4 5 8  1 2 4 5 8\n",
      "\n",
      "Теперь массив полностью отсортирован, но неоптимизированный алгоритм проведет еще два прохода, на которых ничего не изменится, в отличие от алгоритма, использующего вторую оптимизацию, который сделает один проход и прекратит свою работу, так как не сделает за этот проход ни одного обмена.\n",
      "\n",
      " Модификации \n",
      "\n",
      " Сортировка чет-нечет \n",
      "Сортировка чет-нечет (англ. odd-even sort)   модификация пузырьковой сортировки, основанная на сравнении элементов стоящих на четных и нечетных позициях независимо друг от друга. Сложность   O(n^2) .\n",
      "Псевдокод указан ниже:\n",
      " function oddEvenSort(a):\n",
      "   for i = 0 to n - 1 \n",
      "     if i mod 2 == 0\n",
      "       for j = 2 to n - 1 step 2\n",
      "         if a[j] < a[j - 1]\n",
      "           swap(a[j - 1], a[j])  \n",
      "     else      \n",
      "       for j = 1 to n - 1 step 2\n",
      "         if a[j] < a[j - 1]\n",
      "           swap(a[j - 1], a[j])\n",
      "\n",
      "Преимущество этой сортировки  на нескольких процессорах она выполняется быстрее, так как четные и нечетные индексы сортируются параллельно.\n",
      "\n",
      " Сортировка расческой \n",
      "Сортировка расческой (англ. comb sort)   модификация пузырьковой сортировки, основанной на сравнении элементов на расстоянии.  Сложность    O(n^2) , но стремится к          O(n \\log n) .  Является самой быстрой квадратичной сортировкой. Недостаток  она неустойчива. Псевдокод указан ниже:\n",
      "\n",
      " function combSort(a):\n",
      "   k = 1.3\n",
      "   jump = n\n",
      "   bool swapped = true\n",
      "   while jump > 1 and swapped\n",
      "     if jump > 1\n",
      "       jump /= k\n",
      "     swapped = false\n",
      "     for i = 0 to size - jump - 1\n",
      "       if a[i + jump] < a[i]\n",
      "         swap(a[i], a[i + jump])\n",
      "         swapped = true\n",
      "Пояснения: Изначально расстояние между сравниваемыми элементами равно  \\frac{n}{k} , где  k = 1{.}3   оптимальное число для этого алгоритма. Сортируем массив по этому расстоянию, потом уменьшаем его по этому же правилу. Когда  расстояние между сравниваемыми элементами достигает единицы, массив досортировывается обычным пузырьком.\n",
      "\n",
      " Сортировка перемешиванием  \n",
      "Сортировка перемешиванием (англ. cocktail sort), также известная как Шейкерная сортировка    разновидность пузырьковой сортировки, сортирующая массив в двух направлениях на каждой итерации. В среднем, сортировка перемешиванием работает в два раза быстрее пузырька. Сложность    O(n^2) , но стремится она к  O(k \\cdot n) , где  k   максимальное расстояние элемента в неотсортированном массиве от его позиции в отсортированном массиве. Псевдокод указан ниже:\n",
      "\n",
      " function shakerSort(a):\n",
      "   begin = -1\n",
      "   end = n - 2\n",
      "   while swapped\n",
      "     swapped = false   \n",
      "     begin++\n",
      "     for i = begin to end \n",
      "       if a[i] > a[i + 1] \n",
      "         swap(a[i], a[i + 1])\n",
      "         swapped = true    \n",
      "     if !swapped\n",
      "       break    \n",
      "     swapped = false \n",
      "     end--\n",
      "     for i = end downto begin\n",
      "       if a[i] > a[i + 1] \n",
      "         swap(a[i], a[i + 1])\n",
      "         swapped = true\n",
      "\n",
      " См. также \n",
      " Сортировка выбором\n",
      " Сортировка вставками\n",
      " Сортировка кучей\n",
      " Сортировка слиянием\n",
      " Быстрая сортировка\n",
      " Сортировка подсчетом\n",
      "\n",
      " Источники информации \n",
      " Сортировка пузырьком  Википедия\n",
      " Визуализатор\n",
      "  Сортировка чет-нечет  Википедия\n",
      " Сортировка расческой  Википедия\n",
      " Сортировка перемешиванием  Википедия\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировка\n",
      "Категория: Квадратичные сортировки\n",
      "Сортировка вставками (англ. Insertion sort) — квадратичный алгоритм сортировки.\n",
      "\n",
      "Алгоритм\n",
      "Задача заключается в следующем: есть часть массива, которая уже отсортирована, и требуется вставить остальные элементы массива в отсортированную часть, сохранив при этом упорядоченность. Для этого на каждом шаге алгоритма мы выбираем один из элементов входных данных и вставляем его на нужную позицию в уже отсортированной части массива, до тех пор пока весь набор входных данных не будет отсортирован. Метод выбора очередного элемента из исходного массива произволен, однако обычно (и с целью получения устойчивого алгоритма сортировки), элементы вставляются по порядку их появления во входном массиве.\n",
      "\n",
      "Так как в процессе работы алгоритма могут меняться местами только соседние элементы, каждый обмен уменьшает число инверсий на единицу. Следовательно, количество обменов равно количеству инверсий в исходном массиве вне зависимости от реализации сортировки. Максимальное количество инверсий содержится в массиве, элементы которого отсортированы по невозрастанию. Число инверсий в таком массиве \\displaystyle \\frac {n(n - 1)} {2}.\n",
      "\n",
      "Алгоритм работает за O(n + k), где k — число обменов элементов входного массива, равное числу инверсий. В среднем и в худшем случае — за O(n^2). Минимальные оценки встречаются в случае уже упорядоченной исходной последовательности элементов, наихудшие — когда они расположены в обратном порядке.\n",
      "\n",
      "Псевдокод\n",
      " function insertionSort(a):\n",
      "   for i = 1 to n - 1\n",
      "     j = i - 1\n",
      "     while j   \\geqslant  0 and a[j] > a[j + 1] \n",
      "       swap(a[j], a[j + 1])\n",
      "       j--\n",
      "\n",
      "Пример работы\n",
      "Пример работы алгоритма для массива [ 5, 2, 4, 3, 1 ]\n",
      "\n",
      " До После Описание шагаПервый проход (проталкиваем второй элемент — 2) 5 2 4 3 1 2 5 4 3 1 Алгоритм сравнивает второй элемент с первым и меняет их местами.Второй проход (проталкиваем третий элемент — 4) 2 5 4 3 1  2 4 5 3 1 Сравнивает третий со вторым и меняет местами 2 4 5 3 1 2 4 5 3 1 Второй и первый отсортированы, swap не требуетсяТретий проход (проталкиваем четвертый — 3) 2 4 5 3 1 2 4 3 5 1 Меняет четвертый и третий местами 2 4 3 5 1 2 3 4 5 1 Меняет третий и второй местами 2 3 4 5 1 2 3 4 5 1 Второй и первый отсортированы, swap не требуетсяЧетвертый проход (проталкиваем пятый элемент — 1) 2 3 4 5 1 2 3 4 1 5 Меняет пятый и четвертый местами 2 3 4 1 5 2 3 1 4 5 Меняет четвертый и третий местами 2 3 1 4 5 2 1 3 4 5  Меняет третий и второй местами 2 1 3 4 5 1 2 3 4 5 Меняет второй и первый местами. Массив отсортирован.\n",
      " Оптимизации \n",
      " Бинарные вставки \n",
      "Теперь вместо линейного поиска позиции мы будем использовать  бинарный поиск, следовательно количество сравнений изменится с O(N^2) до  O(N\\log N) . Количество сравнений заметно уменьшилось, но для того, чтобы поставить элемент на своё место, всё ещё необходимо переместить большое количество элементов. В итоге время выполнения алгоритма в асимптотически не уменьшилось. Бинарные вставки выгодно использовать только в случае когда сравнение занимает много времени по сравнению со сдвигом. Например когда мы используем массив длинных чисел. \n",
      " function insertionSort(a):\n",
      "   for i = 1 to n - 1\n",
      "     j = i - 1\n",
      "     k = binSearch(a, a[i], 0, j)\n",
      "     for m = j downto k\n",
      "       swap(a[m], a[m+1])\n",
      "\n",
      " Двухпутевые вставки \n",
      "Суть этого метода в том, что вместо отсортированной части массива мы используем область вывода. Первый элемент помещается в середину области вывода, а место для последующих элементов освобождается путём сдвига элементов влево или вправо туда, куда выгоднее.\n",
      "Пример для набора элементов [ 5, 7, 3, 4, 6 ]    \n",
      " До После Описание шагаПервый проход (проталкиваем первый элемент — 5)  5 Так как в поле вывода нет элементов, то мы просто добавляем элемент туда.Второй проход (проталкиваем второй элемент — 7) 5  5 7 С помощью Бинарного поиска находим позицию и, так как позиция крайняя, то сдвигать ничего не приходится.Третий проход (проталкиваем третий — 3) 5 7 3 5 7 С помощью Бинарного поиска находим позицию и, так как позиция крайняя, то сдвигать ничего не приходится.Четвертый проход (проталкиваем четвертый элемент — 4) 3 5 7 3 4 5 7 С помощью Бинарного поиска находим позицию. Расстояние до левого края зоны вывода меньше, чем до правого, значит сдвигаем левую часть.Четвертый проход (проталкиваем пятый элемент — 6) 3 4 5 7 3 4 5 6 7 Расстояние до правого края меньше чем до левого, следовательно двигаем правую часть.    \n",
      "Как можно заметить структура поля вывода имеет сходство с  деком, а именно мы выбираем край к которому ближе наш элемент, затем добавляем с этой стороны наш элемент и двигаем его. Как мы видим в этом примере понадобилось сдвинуть всего 3 элемента. Благодаря тому что для вставки j-ого элемента потребуется j/2 сдвигов в худшем случае вместо j, то и итоговое число необходимых операций в худшем случае составит N^2 / 4 + N \\log N.\n",
      "\n",
      " См. также \n",
      " Сортировка пузырьком\n",
      " Сортировка выбором\n",
      " Сортировка кучей\n",
      " Сортировка слиянием\n",
      " Быстрая сортировка\n",
      " Сортировка подсчетом\n",
      " Сортировка Шелла\n",
      " Источники информации\n",
      " Сортировка вставками\n",
      " Н. Вирт Алгоритмы и структуры данных  Невский Диалект, 2008.  352 с.  ISBN 978-5-7940-0065-8\n",
      " Визуализатор квадратичных алгоритмов\n",
      " Презентация «Сортировка вектора - 3. Insertion Sort»\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Квадратичные сортировки\n",
      "Сортировка кучей, пирамидальная сортировка (англ. Heapsort)  алгоритм сортировки, использующий структуру данных двоичная куча. Это неустойчивый алгоритм сортировки с временем работы O(n\\log{n}) , где n  количество элементов для сортировки, и использующий O(1) дополнительной памяти.\n",
      "\n",
      " Алгоритм \n",
      "Необходимо отсортировать массив A, размером n. Построим на базе этого массива за O(n) кучу для максимума. Так как максимальный элемент находится в корне, то если поменять его местами с A[n - 1], он встанет на своё место. Далее вызовем процедуру  \\mathrm{siftDown(0)} , предварительно уменьшив  \\mathrm{heapSize}  на 1. Она за O(\\log{n}) просеет A[0] на нужное место и сформирует новую кучу (так как мы уменьшили её размер, то куча располагается с A[0] по A[n - 2], а элемент A[n-1] находится на своём месте). Повторим эту процедуру для новой кучи, только корень будет менять местами не с A[n - 1], а с A[n-2]. Делая аналогичные действия, пока  \\mathrm{heapSize}   не станет равен 1, мы будем ставить наибольшее из оставшихся чисел в конец не отсортированной части. Очевидно, что таким образом, мы получим отсортированный массив.\n",
      "\n",
      " Реализация \n",
      "\\mathrm{A}  массив, который необходимо отсортировать\n",
      "\\mathrm{n}  количество элементов в нём\n",
      " \\mathrm{buildHeap(A)}   процедура, которая строит из передаваемого массива кучу для максимума в этом же массиве\n",
      " \\mathrm{siftDown(A, i, len)}   процедура, которая просеивает вниз элемент  \\mathrm{A[i]}  в куче из  \\mathrm{len}  элементов, находящихся в начале массива  \\mathrm{A} \n",
      "  fun heapSort(A : list <T>):\n",
      "    buildHeap(A)\n",
      "    heapSize = A.size\n",
      "    for i = 0 to n - 1\n",
      "      swap(A[0], A[n - 1 - i])\n",
      "      heapSize--\n",
      "      siftDown(A, 0, heapSize)\n",
      "\n",
      " Сложность \n",
      "Операция  \\mathrm{siftDown}  работает за O(\\log{n}). Всего цикл выполняется (n - 1) раз. Таким образом сложность сортировки кучей является O(n\\log{n}).\n",
      "\n",
      "Достоинства:\n",
      " худшее время работы  O(n\\log{n}),\n",
      " требует O(1) дополнительной памяти.\n",
      "Недостатки:\n",
      " неустойчивая,\n",
      " на почти отсортированных данных работает столь же долго, как и на хаотических данных.\n",
      "\n",
      " Пример \n",
      "\n",
      "  155px|thumb|Строим кучу\n",
      " 155px|thumb|Первый проход\n",
      " 155px|thumb|Строим новую кучу\n",
      "  155px|thumb|Второй проход\n",
      " 155px|thumb|Третий проход\n",
      " 155px|thumb|Четвёртый проход\n",
      " \n",
      "\n",
      "Пусть дана последовательность из 5 элементов 3, 2, 4, 1, 5.\n",
      "\n",
      " Массив Описание шага 5 3 4 1 2 Строим кучу из исходного массива Первый проход 2 3 4 1 5 Меняем местами первый и последний элементы  4 3 2 1 5 Строим кучу из первых четырёх элементовВторой проход 1 3 2 4 5 Меняем местами первый и четвёртый элементы  3 1 2 4 5 Строим кучу из первых трёх элементовТретий проход 2 1 3 4 5 Меняем местами первый и третий элементы  2 1 3 4 5 Строим кучу из двух элементовЧетвёртый проход 1 2 3 4 5 Меняем местами первый и второй элементы   1 2 3 4 5 Массив отсортирован\n",
      "\n",
      " JSort \n",
      "JSort является модификацией сортировки кучей, которую придумал Джейсон Моррисон (Jason Morrison).\n",
      "Алгоритм частично упорядочивает массив, строя на нём два раза кучу: один раз передвигая меньшие элементы влево, второй раз передвигая большие элементы вправо. Затем к массиву применяется\n",
      "сортировка вставками, которая при почти отсортированных данных работает за O(n).\n",
      "\n",
      "Достоинства:\n",
      "В отличие от сортировки кучей, на почти отсортированных массивах работает быстрее, чем на случайных.\n",
      "В силу использования сортировки вставками, которая просматривает элементы последовательно, использование кэша гораздо эффективнее.\n",
      "Недостатки:\n",
      "На длинных массивах, возникают плохо отсортированные последовательности в середине массива, что приводит к ухудшению работы сортировки вставками.\n",
      " \n",
      " Алгоритм \n",
      "Построим кучу для минимума на этом массиве. \n",
      "Тогда наименьший элемент окажется на первой позиции, а левая часть массива окажется почти отсортированной, так как ей будут соответствовать верхние узлы кучи.\n",
      "Теперь построим на этом же массиве кучу так, чтобы немного упорядочить правую часть массива. Эта куча должна быть кучей для максимума и быть \"зеркальной\" к массиву, то есть чтобы её корень соответствовал последнему элементу массива.\n",
      "К получившемуся массиву применим сортировку вставками.\n",
      "\n",
      " Сложность \n",
      "\n",
      "Построение кучи занимает O(n). Почти упорядоченный массив сортировка вставками может отсортировать  O(n), но в худшем случае за O(n^2).\n",
      "\n",
      "Таким образом, наихудшая оценка Jsort  O(n^2).\n",
      "\n",
      " Пример \n",
      "Рассмотрим, массив  A  =  [1, 2, 8, 15, 17, 20, 31, 32, 30, 2, 3, 5, 10, 11, 24 ] \n",
      "\n",
      "Построим на этом массиве кучу для минимума:\n",
      " 400px \n",
      "Массив выглядит следующим образом:\n",
      " 400px \n",
      "Заметим, что начало почти упорядочено, что хорошо скажется на использовании сортировки вставками.\n",
      "\n",
      "Построим теперь зеркальную кучу для максимума на этом же массиве.\n",
      " 400px \n",
      "Массив будет выглядеть следующим образом:\n",
      " 400px \n",
      "Теперь и конец массива выглядит упорядоченным, применим сортировку вставками и получим отсортированный массив.\n",
      "\n",
      " См. также \n",
      " Сортировка слиянием\n",
      " Быстрая сортировка\n",
      " Теорема о нижней оценке для сортировки сравнениями\n",
      "\n",
      " Источники информации \n",
      " Кормен Т., Лейзерсон Ч., Ривест Р., Штайн К. Алгоритмы: построение и анализ, 2-е издание. Издательский дом \"Вильямс\", 2005. ISBN 5-8459-0857-4\n",
      "Wikipedia  Heapsort\n",
      " Wikipedia  JSort\n",
      "Хабрахабр  Описание сортировки кучей и JSort\n",
      "Википедия  Пирамидальная сортировка\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Сортировка Шелла (англ. Shellsort) — алгоритм сортировки, являющийся усовершенствованным вариантом сортировки вставками. \n",
      "\n",
      "Алгоритм\n",
      "Каждый проход в алгоритме характеризуется смещением h_i, таким, что сортируются элементы отстающие друг от друга на h_i позиций.\n",
      "Шелл предлагал использовать h_t = N/2, h_{t-1} = h_t/2, \\ldots , h_0 = 1. Возможны и другие смещения, но h_0 = 1 всегда.\n",
      "\n",
      " Начало.\n",
      " Шаг 0. i = t.\n",
      " Шаг 1. Разобьем массив на списки элементов, отстающих друг от друга на h_i. Таких списков будет h_i.\n",
      " Шаг 2. Отсортируем элементы каждого списка сортировкой вставками.\n",
      " Шаг 3. Объединим списки обратно в массив. Уменьшим i. Если i неотрицательно — вернемся к шагу 1\n",
      " Конец.\n",
      "\n",
      "Пример\n",
      "Возьмем массив A= \\{ 56, 43, 12, 78, 42, 93, 16, 55 \\}  и смещения предложенные Шеллом.\n",
      " До После Описание шага Шаг 1 i = t = 2 56, 43, 12, 78, 42, 93, 16, 55 \\{ 56, 42 \\}  \\{ 43, 93 \\}  \\{ 12, 16 \\}  \\{ 78, 55 \\}  Разбили массив на 4 списка. Шаг 2 \\{ 56, 42 \\}  \\{ 43, 93 \\}  \\{ 12, 16 \\}  \\{ 78, 55 \\}  \\{ 42, 56 \\}  \\{ 43, 93 \\}  \\{ 12, 16 \\}  \\{ 55, 78 \\}  Отсортировали элементы списков сортировкой вставками. Количество обменов 2. Шаг 3 \\{ 42, 56 \\}  \\{ 43, 93 \\}  \\{ 12, 16 \\}  \\{ 55, 78 \\}  42, 43, 12, 55, 56, 93, 16, 78 Объединили списки в массив. Уменьшаем i на 1. i \\geqslant 0, перейдем к шагу 1. Шаг 1 i = 1 42, 43, 12, 55, 56, 93, 16, 78 \\{ 42, 12, 56, 16 \\}  \\{ 43, 55, 93, 78 \\}  Разбили массив на 2 списка. Шаг 2 \\{ 42, 12, 56, 16 \\}  \\{ 43, 55, 93, 78 \\}  \\{ 12, 16, 42, 56 \\}  \\{ 43, 55, 78, 93 \\}  Отсортировали элементы списков сортировкой вставками. Количество обменов 4. Шаг 3 \\{ 12, 16, 42, 56 \\}  \\{ 43, 55, 78, 93 \\}  12, 43, 16, 55, 42, 78, 56, 93 Объединили списки в массив. Уменьшаем i на 1. i \\geqslant 0, перейдем к шагу 1. Шаг 1 i = 0 42, 43, 12, 55, 56, 93, 16, 78 \\{ 42, 43, 12, 55, 56, 93, 16, 78 \\}  Разбили массив на 1 список. Шаг 2 \\{ 42, 43, 12, 55, 56, 93, 16, 78 \\}  \\{ 12, 16, 42, 43, 55, 56, 78, 93 \\}  Отсортировали элементы списков сортировкой вставками. Количество обменов 7. Шаг 3 \\{ 12, 16, 42, 43, 55, 56, 78, 93 \\}  12, 16, 42, 43, 55, 56, 78, 93 Объединили списки в массив. Уменьшаем i на 1. i<0.\n",
      "Анализ метода Шелла\n",
      "Понятно, что сложность алгоритма зависит от оптимальности выбора набора h_i.\n",
      "Массив, где для любого i верно  a_i \\leqslant a_{i+h}, назовем h упорядоченным.\n",
      "\n",
      "Следующая лемма является следствием теоремы выше.\n",
      "\n",
      "Доказательство данных теоремы и леммы изложено в книге, предложенной к прочтению.\n",
      "\n",
      "В первом приближении функция f(n,h) равна  (\\sqrt{\\pi}/8)n^{3/2}h^{1/2}. Следовательно D для двух проходов будет примерно пропорционально 2N^2/h+\\sqrt{\\pi N^3h}. Поэтому наилучшее значение h равно приблизительно \\sqrt[3]{16N/ {\\pi}} \\approx 1.72\\sqrt[3]{N}, при таком выборе h среднее время сортировки пропорционально N^{5/3}.\n",
      "\n",
      "Таким образом, применяя метод Шелла и используя всего 2 прохода, можно сократить  время по сравнению с методом простых вставок с O(N^2) до O(N^{1.(6)}).\n",
      "\n",
      "Используя приведенные выше формулы, порог N^{1.5} преодолеть невозможно, но если убрать ограничение  h_{s+1}\\,\\bmod\\,h_s = 0 его можно преодолеть.\n",
      "\n",
      "Важно, что эта теорема дает оценку времени выполнения алгоритма в худшем случае.\n",
      "\n",
      "Дальнейшее улучшение было получено Волганом Праттом. Если все смещения при сортировке выбираются из множества чисел вида 2^p3^q, меньших N, то время выполнения алгоритма будет порядка O(N\\log^2{N}).\n",
      "\n",
      " См. также \n",
      " Сортировка выбором\n",
      " Сортировка вставками\n",
      " Быстрая сортировка\n",
      "\n",
      " Источники информации \n",
      " Дональд Кнут — Искусство программирования, том 3. Сортировка и поиск = The Art of Computer Programming, vol.3. Sorting and Searching. — 2-е изд. — М.: «Вильямс», 2007. — 824 с. — ISBN 5-8459-0082-4\n",
      " Сортировка Шелла — Википедия\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировка\n",
      "Категория: Сортировка на сравнениях\n",
      "Быстрая сортировка (англ. quick sort, сортировка Хоара)  один из самых известных и широко используемых алгоритмов сортировки. Среднее время работы O(n\\log{n}), что является асимптотически оптимальным временем работы для алгоритма, основанного на сравнении. Хотя время работы алгоритма для массива из n элементов в худшем случае может составить \\Theta(n^2), на практике этот алгоритм является одним из самых быстрых.\n",
      "\n",
      "Алгоритм\n",
      "Быстрый метод сортировки функционирует по принципу \"разделяй и властвуй\". \n",
      " Массив  a[l \\ldots r] типа  T  разбивается на два (возможно пустых) подмассива  a[l \\ldots q] и  a[q+1 \\ldots r], таких, что каждый элемент  a[l \\ldots q] меньше или равен  a[q], который в свою очередь, не превышает любой элемент подмассива  a[q+1 \\ldots r]. Индекс  вычисляется  в ходе процедуры разбиения.\n",
      " Подмассивы  a[l \\ldots q] и  a[q+1 \\ldots r] сортируются с помощью рекурсивного вызова процедуры быстрой сортировки.\n",
      " Поскольку подмассивы сортируются на месте, для их объединения не требуются никакие действия: весь массив  a[l \\ldots r] оказывается отсортированным.\n",
      "\n",
      "Псевдокод\n",
      "   void quicksort(a: T[n], int l, int r)\n",
      "      if l < r\n",
      "         int q = partition(a, l, r)\n",
      "         quicksort(a, l, q)\n",
      "         quicksort(a, q + 1, r)\n",
      "Для сортировки всего массива необходимо выполнить процедуру \\mathrm{quicksort(a, 0, length[a] - 1)}.\n",
      "\n",
      "Разбиение массива\n",
      "Основной шаг алгоритма сортировки  процедура \\mathrm{partition}, которая переставляет элементы массива a[l \\ldots r] типа  T  нужным образом.\n",
      "Разбиение осуществляется с использованием следующей стратегии. Прежде всего, в качестве разделяющего элемента произвольно выбирается элемент \n",
      " a[(l + r) / 2] . Далее начинается просмотр с левого конца массива, который продолжается до тех пор, пока не будет найден элемент, превосходящий по значению разделяющий элемент, затем выполняется просмотр, начиная с правого конца массива, который продолжается до тех пор, пока не отыскивается элемент, который по значению меньше разделяющего. Оба элемента, на которых просмотр был прерван, очевидно, находятся не на своих местах в разделенном массиве, и потому они меняются местами. Так продолжаем дальше, пока не убедимся в том, что слева от левого указателя не осталось ни одного элемента, который был бы больше по значению разделяющего, и ни одного элемента справа от правого указателя, которые были бы меньше по значению разделяющего элемента.\n",
      "\n",
      "Переменная  v  сохраняет значение разделяющего элемента  a[(l + r) / 2] , a  i  и  j  представляет собой, соответственно, указатели левого и правого просмотра. Цикл разделения увеличивает значение  i  и уменьшает значение  j  на  1 , причем условие, что ни один элемент слева от  i  не больше  v  и ни один элемент справа от  j  не меньше   v , не нарушается. Как только значения указателей пересекаются, процедура разбиения завершается.\n",
      "\n",
      "   int partition(a: T[n], int l, int r)\n",
      "      T v = a[(l + r) / 2]\n",
      "      int i = l\n",
      "      int j = r\n",
      "      while (i  \\leqslant  j) \n",
      "         while (a[i] < v)\n",
      "            i++\n",
      "         while (a[j] > v)\n",
      "            j--\n",
      "         if (i  \\geqslant  j) \n",
      "            break\n",
      "         swap(a[i++], a[j--])\n",
      "      return j\n",
      "\n",
      "Асимптотика\n",
      "Худшее время работы\n",
      "Предположим, что мы разбиваем массив так, что одна часть содержит n - 1 элементов, а вторая  1. Поскольку процедура разбиения занимает время \\Theta(n), для времени работы T(n) получаем соотношение:\n",
      "\n",
      "T(n) = T(n - 1) + \\Theta(n) = \\sum\\limits_{k=1}^{n} \\Theta(k) = \\Theta(\\sum\\limits_{k=1}^{n} k) = \\Theta(n^2).\n",
      "\n",
      "Мы видим, что при максимально несбалансированном разбиении время работы составляет \\Theta(n^2). В частности, это происходит, если массив изначально отсортирован.\n",
      "\n",
      "Способ построить массив с максимальным количеством сравнений при выборе среднего элемента в качестве опорного\n",
      "В некоторых алгоритмах быстрой сортировки в качестве опорного выбирается элемент, который стоит в середине рассматриваемого массива. Рассмотрим массив, на котором быстрая сортировка с выбором среднего элемента в качестве опорного сделает \\Theta(n^2) сравнений. Очевидно, что это будет достигаться при худшем случае (когда при каждом разбиении в одном массиве будет оказываться 1, а в другом  n - 1  элемент).\n",
      "\n",
      "Заполним сначала массив a длины n элементами от 1 до  n , затем применим следующий алгоритм (нумерация с нуля):\n",
      " \n",
      "   void antiQsort(a: T[n])\n",
      "      for i = 0 to n - 1 \n",
      "         swap(a[i], a[i / 2])\n",
      "Тогда на каждом шаге в качестве среднего элемента будет ставиться самый крупный элемент.\n",
      "\n",
      "При выполнении \\mathrm{partition} делается \\Theta(n) сравнений из-за того, что с помощью индексов i и j мы проходим в лучшем случае \\Omega(n) элементов (если функция прекращает свою работу, как только индексы встречаются), в худшем случае O(2n) элементов (если оба индекса полностью проходят массив). При каждом изменении индекса делается сравнение, значит, процедура \\mathrm{partition} делает \\Theta(n) сравнений с точностью до константы.\n",
      "\n",
      "Рассмотрим, какой элемент будет выбираться опорным на каждом шаге. \\mathrm{antiQsort} на каждом шаге меняет местами последний и центральный элементы, поэтому в центре оказывается самый крупный элемент. А \\mathrm{partition} делает абсолютно симметричные этой процедуре операции, но в другую сторону: меняет местами центральный элемент с последним, так что самый крупный элемент становится последним, а затем выполняет на массиве длины на один меньшей ту же операцию. Получается, что опорным всегда будет выбираться самый крупный элемент, так как  \\mathrm{antiQsort}  на массиве любой длины будет выполнять операции, обратные \\mathrm{partition}. Фактически, \\mathrm{partition}  это \\mathrm{antiQsort}, запущенная в другую сторону. Также стоит отметить, что процедура разбиения будет делать на каждом шаге только одну смену элементов местами. Сначала i дойдет до середины массива, до опорного элемента, j останется равным индексу последнего элемента. Затем произойдет \\mathrm{swap} и i снова начнет увеличиваться, пока не дойдет до последнего элемента, j опять не изменит свою позицию. Потом произойдет выход из \\mathrm{while}.\n",
      "\n",
      "Разбиение массива будет произведено \\Theta(n) раз, потому что разбиение производится на массивы длины 1 и  n - 1  из-за того, что на каждом шаге разбиения в качестве опорного будет выбираться самый крупный элемент (оценка на худшее время работы доказана выше).  Следовательно, на массиве, который строится описанным выше способом, выполняется \\Theta(n) \\mathrm{partition} и \\Theta(n) сравнений для каждого выполнения \\mathrm{partition}. Тогда быстрая сортировка выполнит \\Theta(n^2) сравнений для массива, построенного таким способом.\n",
      "\n",
      "Способ построить массив с максимальным количеством сравнений при детерминированном выборе опорного элемента\n",
      "\n",
      "Рассмотрим алгоритм построения массива, на котором быстрая сортировка с детерминированным выбором опорного элемента будет делать максимальное (в данном случае  \\Theta(n^2)) количество сравнений. Такое число сравнений достигается при разбиении на массивы длиной 1 и n-1 на каждой итерации.  \n",
      "Создадим массив a длины n, заполненный элементами типа pair. Такой элемент хранит пару значений (val, key), где val  элемент массива, а key  индекс. Изначально  a[i] элемент имеет вид (0, i).\n",
      "\n",
      "Далее, запустим для данного массива алгоритм быстрой сортировки. Сравниваем два элемента типа pair по их значениям val. На каждом шаге будем выполнять следующие действия: при обращении к i-ому элементу в качестве опорного на шаге под номером k, присвоим val = n-k+1 для элемента a[i]. Затем выполним шаг сортировки. После завершения работы алгоритма быстрой сортировки, дополнительно отсортируем получившиеся элементы pair по значениям key. Искомым будет являться массив элементов val в соответствующей последовательности. \n",
      " \n",
      "Пример для n = 4, при последовательном выборе опорных элементов 2, 2, 1, 1.\n",
      "\n",
      " Построение массива Шаг 1.0  Шаг 1.1  Шаг 1.2  Шаг 2.0  Шаг 2.1  Шаг 2.2  Шаг 3.01 2 3 4  0 0 0 01 2 3 4  0 4 0 01 4 3 2  0 0 0 41 4 3 2  0 0 0 41 4 3 2  0 3 0 41 3 4 2  0 0 3 41 3 4 2  0 0 3 4 Шаг 3.1  Шаг 3.2  Шаг 4.0  Шаг 4.1  Шаг 4.2  Результат1 3 4 2  2 0 3 43 1 4 2  0 2 3 43 1 4 2  0 2 3 43 1 4 2  1 2 3 43 1 4 2  1 2 3 41 2 3 4  2 4 1 3 Итоговый массив2 4 1 3\n",
      "\n",
      "Покажем, почему на данном массиве будет достигаться максимальное время работы быстрой сортировки. На этапе построения мы каждый раз присваивали опорному элементу максимальное значение. Следовательно, при выполнении \\mathrm{quicksort} алгоритм в качестве опорного всегда будет выбирать наибольший элемент массива (выборка будет производится в том же порядке ввиду детерминированности определения опорного элемента). \n",
      "Таким образом, так как каждый раз массив разбивается на две части  большие или равные опорному элементы и меньшие его  на каждом шаге имеем разбиение на массивы длины 1 и n-1, чего мы, собственно, и добивались. При таком выполнении алгоритма происходит \\Theta(n^2) разделений на два подмассива, и на каждом разделении выполняется \\Theta(n^2) сравнений. \n",
      "Следовательно, на данном массиве быстрая сортировка работает за \\Theta(n^2).\n",
      "\n",
      "Среднее время работы\n",
      "\n",
      "Mатожидание времени работы быстрой сортировки будет O(n \\log n).\n",
      "\n",
      "Модификации\n",
      "\n",
      "Нерекурсивная реализация быстрой сортировки\n",
      "Для выполнения быстрой сортировки можно воспользоваться  стеком, в котором в виде сортируемых подмассивов содержится перечень действий, которые предстоит выполнить. Каждый раз когда возникает необходимость в обработке подмассива, он выталкивается из стека. После разделения массива получаются два подмассива, требующих дальнейшей обработки, которые и заталкиваются в стек.\n",
      "Представленная ниже нерекурсивная реализация использует стек, заменяя рекурсивные вызовы помещением в стек параметров функции, а вызовы процедур и выходы из них — циклом, который осуществляет выборку параметров из стека и их обработку, пока стек не пуст. Мы помещаем больший из двух подмассивов в стек первым с тем, чтобы максимальная глубина стека при сортировке N элементов не превосходила величины \\log n. \n",
      "   void quicksort(a: T[n], int l, int r)\n",
      "      stack< pair<int,int> > s   \n",
      "      s.push(l, r)\n",
      "      while (s.isNotEmpty)\n",
      "         (l, r) = s.pop()\n",
      "         if (r  \\leqslant  l)\n",
      "            continue\n",
      "         int i = partition(a, l, r)\n",
      "         if (i - l > r - i) \n",
      "            s.push(l, i - 1)\n",
      "            s.push(i + 1, r)\n",
      "         else\n",
      "            s.push(i + 1, r)\n",
      "            s.push(l, i - 1)\n",
      "\n",
      "В качестве альтернативного варианта можно использовать обычную рекурсивную версию, в которой вместо того, чтобы после разделения массива вызывать рекурсивно процедуру разделения для обоих найденных подмассивов, рекурсивный вызов делается только для меньшего подмассива, а больший обрабатывается в цикле в пределах этого же вызова процедуры. С точки зрения эффективности в среднем случае разницы практически нет: накладные расходы на дополнительный рекурсивный вызов и на организацию сравнения длин подмассивов и цикла — примерно одного порядка. Зато глубина рекурсии ни при каких обстоятельствах не превысит \\log n, а в худшем случае вырожденного разделения она вообще будет не более 1 — вся обработка пройдёт в цикле первого уровня рекурсии.\n",
      "\n",
      "Улучшенная быстрая сортировка\n",
      "\n",
      "Выбор медианы из первого, среднего и последнего элементов в качестве разделяющего элемента и отсечение рекурсии меньших подмассивов может \n",
      "привести к существенному повышению эффективности быстрой сортировки. Функция \\mathrm{median} возвращает индекс элемента, являющегося медианой трех элементов. После этого он и средний элемент массива меняются местами, при этом медиана становится разделяющим элементом. Массивы небольшого размера (длиной  M = 11 и меньше) в процессе разделения игнорируются, затем для окончания сортировки используется  сортировка вставками. \n",
      "\n",
      "   const int M = 10\n",
      "   void quicksort(a: T[n], int l, int r)\n",
      "      if (r - l  \\leqslant  M)\n",
      "         insertion(a, l, r)\n",
      "         return\n",
      "      int med = median(a[l], a[(l + r) / 2], a[r])\n",
      "      swap(a[med], a[(l + r) / 2])\n",
      "      int i = partition(a, l, r)\n",
      "      quicksort(a, l, i)\n",
      "      quicksort(a, i + 1, r)\n",
      "\n",
      "Вообще, можно применять любые эвристики по выбору опорного элемента. Например, в стандартной реализации в Java в качестве разделяющего выбирается средний из 7 элементов, равномерно распределённых по массиву.\n",
      "\n",
      "Быстрая сортировка с разделением на три части\n",
      "\n",
      "Когда в сортируемом массиве имеется множество повторяющихся ключей предыдущие реализации быстрой сортировки можно существенно улучшить. Например массив, который состоит из равных ключей, вовсе не нуждается в дальнейшей сортировке, однако предыдущие реализации продолжают процесс разделения, подвергая обработке все более мелкие подмассивы, независимо от того, насколько большим является исходный файл. \n",
      "\n",
      "В основу программы положено разделение массива на три части: \n",
      "на элементы,меньшие разделяющего элемента  a[l] \\ldots a[i], \n",
      "элементы, равные разделяющему элементу a[i+1] \\ldots a[j-1],\n",
      "и элементы большие разделяющего элемента a[j] \\ldots a[r]. \n",
      "После этого сортировка завершается двумя рекурсивными вызовами.\n",
      "\n",
      "400px|thumb|center| Разделение массива  a \n",
      "\n",
      "Элементы массива равные разделяющему элементу находятся между  l  и  p  и между  q  и   r . В разделяющем цикле, когда указатели просмотра перестают изменяться и выполняется обмен значениями  i  и  j , каждый из этих элементов проверяется на предмет равенства разделяющему элементу. Если элемент, который сейчас находится слева, равен разделяющему элементу, то при помощи операции обмена он помещается в левую часть массива, если элемент, который сейчас находится справа, равен разделяющему элементу, то в результате операции обмена он помещается в правую часть массива. \n",
      "После того как указатели пересекутся, элементы, равные разделяющему элементу и находящиеся на разных концах массива, после операции обмена попадают в свои \n",
      "окончательные позиции. После этого указанные ключи могут быть исключены из подмассивов, для которых выполняются последующие рекурсивные вызовы. \n",
      "\n",
      "   void quicksort(a: T[n], int l, int r)\n",
      "      T v = a[r]\n",
      "      if (r  \\leqslant  l)\n",
      "         return\n",
      "      int i = l\n",
      "      int j = r - 1\n",
      "      int p = l - 1\n",
      "      int q = r\n",
      "      while (i  \\leqslant  j) \n",
      "         while (a[i] < v) \n",
      "            i++\n",
      "         while (a[j] > v) \n",
      "            j--\n",
      "         if (i  \\geqslant  j)\n",
      "            break\n",
      "         swap(a[i], a[j])\n",
      "         if (a[i] == v)\n",
      "            p++\n",
      "            swap(a[p], a[i])\n",
      "         i++\n",
      "         if (a[j] == v)\n",
      "            q--\n",
      "            swap(a[q], a[j])\n",
      "         j--\n",
      "      swap(a[i], a[r])\n",
      "      j = i - 1\n",
      "      i++\n",
      "      for (int k = l; k  \\leqslant  p; k++, j--) \n",
      "         swap(a[k], a[j])\n",
      "      for (int k = r - 1; k  \\geqslant  q; k--, i++) \n",
      "         swap(a[k], a[i]) \n",
      "      quicksort(a, l, j) \n",
      "      quicksort(a, i, r)\n",
      "\n",
      "Параллельная сортировка\n",
      "\n",
      "Еще одной оптимизацией является параллельная сортировка на основе быстрой. \n",
      "Пусть, исходный набор данных расположен на первом процессоре, с него начинается работа алгоритма. Затем исходный массив окажется разделенным на две части, меньшая из которых передастся другому свободному процессору, большая останется на исходном для дальнейшей обработки. Далее обе части опять будут разделены и опять на двух исходных останутся большие части, а меньшие отправятся другим процессорам. В этом заключается ускорение алгоритма. При задействовании всех процессоров, все части параллельно будут сортироваться последовательным алгоритмом.\n",
      "\n",
      "Introsort\n",
      "\n",
      "Для предотвращения ухудшения времени работы быстрой сортировки до O(n^2) при неудачных входных данных, также можно использовать алгоритм сортировки Introsort.\n",
      "Он использует быструю сортировку и переключается на пирамидальную сортировку, когда глубина рекурсии превысит некоторый заранее установленный уровень (например, логарифм от числа сортируемых элементов). Так как после нескольких итераций быстрой сортировки с применением разных эвристик массив с большей вероятностью окажется «почти отсортированным», то пирамидальная сортировка может довольно быстро закончить дело. Также, пирамидальная сортировка хороша тем, что требует O(1) дополнительной памяти, в отличие от, например, сортировки слиянием, где потребуется O(n) дополнительной памяти.\n",
      "\n",
      "См. также\n",
      " Сортировка Шелла\n",
      " Сортировка кучей\n",
      " Сортировка слиянием\n",
      " Timsort\n",
      " Smoothsort\n",
      " PSRS-сортировка\n",
      "\n",
      " Источники информации \n",
      " Википедия  Быстрая сортировка\n",
      " Wikipedia  Quicksort\n",
      " Wikipedia  Introsort\n",
      " Т. Кормен, Ч. Лейзерсон, Р. Ривест: Алгоритмы: построение и анализ глава 7\n",
      " Р. Седжвик: Фундаментальные алгоритмы на С++ части 1 - 4\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировка\n",
      "Категория: Сортировки на сравнениях\n",
      "Сортировка слиянием (англ. Merge sort)  алгоритм сортировки, использующий O(n) дополнительной памяти и работающий за O(n\\log(n)) времени.\n",
      "\n",
      "Принцип работы\n",
      "270px|right|thumb|Пример работы процедуры слияния.\n",
      "\n",
      "300px|right|thumb|Пример работы рекурсивного алгоритма сортировки слиянием\n",
      "\n",
      "300px|right|thumb|Пример работы итеративного алгоритма сортировки слиянием\n",
      "\n",
      "Алгоритм использует принцип «разделяй и властвуй»: задача разбивается на подзадачи меньшего размера, которые решаются по отдельности, после чего их решения комбинируются для получения решения исходной задачи. Конкретно процедуру сортировки слиянием можно описать следующим образом:\n",
      "\n",
      " Если в рассматриваемом массиве один элемент, то он уже отсортирован  алгоритм завершает работу.\n",
      " Иначе массив разбивается на две части, которые сортируются рекурсивно.\n",
      " После сортировки двух частей массива к ним применяется процедура слияния, которая по двум отсортированным частям получает исходный отсортированный массив.\n",
      "\n",
      "Слияние двух массивов\n",
      "У нас есть два массива a и b (фактически это будут две части одного массива, но для удобства будем писать, что у нас просто два массива). Нам надо получить массив c размером |a| + |b|. Для этого можно применить процедуру слияния. Эта процедура заключается в том, что мы сравниваем элементы массивов (начиная с начала) и меньший из них записываем в финальный. И затем, в массиве у которого оказался меньший элемент, переходим к следующему элементу и сравниваем теперь его. В конце, если один из массивов закончился, мы просто дописываем в финальный другой массив. После мы наш финальный массив записываем заместо двух исходных и получаем отсортированный участок.\n",
      "\n",
      "Множество отсортированных списков с операцией \\mathrm{merge} является моноидом, где нейтральным элементом будет пустой список.\n",
      "\n",
      "Ниже приведён псевдокод процедуры слияния, который сливает две части массива a  [left; mid) и [mid; right)\n",
      " function merge(a : int[n]; left, mid, right : int):\n",
      "     it1 = 0\n",
      "     it2 = 0\n",
      "     result : int[right - left]\n",
      "   \n",
      "     while left + it1 < mid and mid + it2 < right\n",
      "         if a[left + it1] < a[mid + it2]\n",
      "             result[it1 + it2] = a[left + it1]\n",
      "             it1 += 1\n",
      "         else\n",
      "             result[it1 + it2] = a[mid + it2]\n",
      "             it2 += 1\n",
      "   \n",
      "     while left + it1 < mid\n",
      "         result[it1 + it2] = a[left + it1]\n",
      "         it1 += 1\n",
      "   \n",
      "     while mid + it2 < right\n",
      "         result[it1 + it2] = a[mid + it2]\n",
      "         it2 += 1\n",
      "   \n",
      "     for i = 0 to it1 + it2\n",
      "         a[left + i] = result[i]\n",
      "\n",
      "Рекурсивный алгоритм\n",
      "Функция сортирует подотрезок массива с индексами в полуинтервале [left; right).\n",
      " function mergeSortRecursive(a : int[n]; left, right : int):\n",
      "     if left + 1 >= right\n",
      "         return\n",
      "     mid = (left + right) / 2\n",
      "     mergeSortRecursive(a, left, mid)\n",
      "     mergeSortRecursive(a, mid, right)\n",
      "     merge(a, left, mid, right)\n",
      "\n",
      "Итеративный алгоритм\n",
      "При итеративном алгоритме используется на O(\\log n) меньше памяти, которая раньше тратилась на рекурсивные вызовы.\n",
      " function mergeSortIterative(a : int[n]):\n",
      "     for i = 1 to n, i *= 2\n",
      "         for j = 0 to n - i, j += 2 * i\n",
      "             merge(a, j, j + i, min(j + 2 * i, n))\n",
      "\n",
      "Время работы\n",
      "Чтобы оценить время работы этого алгоритма, составим рекуррентное соотношение. Пускай T(n)  время сортировки массива длины n, тогда для сортировки слиянием справедливо T(n)=2T(n/2)+O(n) \n",
      "O(n)  время, необходимое на то, чтобы слить два массива длины n. Распишем это соотношение:\n",
      "\n",
      "T(n)=2T(n/2)+O(n)=4T(n/4)+2O(n)=\\dots=T(1)+\\log(n)O(n)=O(n\\log(n)).\n",
      "\n",
      "Сравнение с другими алгоритмами\n",
      "Достоинства:\n",
      " устойчивая,\n",
      " можно написать эффективную многопоточную сортировку слиянием,\n",
      " сортировка данных, расположенных на периферийных устройствах и не вмещающихся в оперативную памятьWikipedia  External sorting.\n",
      "Недостатки:\n",
      " требуется дополнительно O(n) памяти, но можно модифицировать до O(1).\n",
      "\n",
      "См. также\n",
      " Сортировка кучей\n",
      " Быстрая сортировка\n",
      " Timsort\n",
      " Cортировка слиянием с использованием O(1) дополнительной памяти\n",
      "\n",
      "Примечания\n",
      "\n",
      "Источники информации\n",
      "Википедия  сортировка слиянием\n",
      "Визуализатор\n",
      "Викиучебник  Примеры реализации на различных языках программирования\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Сортировки на сравнениях\n",
      "Сортировка сравнениями (англ. Comparison sort)  алгоритм  сортировки, который совершает операции сравнения элементов, но никак не использует их внутреннюю структуру.\n",
      "\n",
      "Следствия\n",
      "\n",
      " См. также \n",
      " Сортирующие_сети\n",
      " Быстрая_сортировка\n",
      " Двоичная_куча\n",
      "\n",
      "Источники информации\n",
      " Кормен, Т., Лейзерсон, Ч., Ривест, Р., Штайн, К. Глава 8. Сортировка за линейное время // Алгоритмы: построение и анализ = Introduction to Algorithms / Под ред. И. В. Красикова. — 2-е изд. — М.: Вильямс, 2005. — 1296 с\n",
      " Андрей Калинин Сортировка за линейное время\n",
      " Конспект по курсу \"Алгоритмы и алгоритмические языки\" (доказательство теоремы через формулу Стирлинга).\n",
      " Лекториум \"Алгоритмы сортировки\"\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Сортировки на сравнениях\n",
      "Сортировка подсчётом (англ. counting sort)  алгоритм сортировки целых чисел в диапазоне от 0 до некоторой константы k или сложных объектов, работающий за линейное время.\n",
      " Сортировка целых чисел \n",
      "Это простейший вариант алгоритма.\n",
      " Описание \n",
      "Исходная последовательность чисел длины n, а в конце отсортированная, хранится в массиве A. Также используется вспомогательный массив C с индексами от 0 до \\mathrm k - 1, изначально заполняемый нулями.\n",
      "\n",
      " Последовательно пройдём по массиву A и запишем в C[i] количество чисел, равных i.\n",
      "\n",
      " Теперь достаточно пройти по массиву C и для каждого number \\in \\{0, ..., \\mathrm k - 1\\} в массив A последовательно записать число number\\  C[number] раз.\n",
      "\n",
      " Псевдокод \n",
      " function simpleCountingSort(A: int[n]): \n",
      "     for number = 0 to k - 1\n",
      "         C[number] = 0 \n",
      "     for i = 0 to n - 1\n",
      "         C[A[i]] = C[A[i]] + 1;     \n",
      "     pos = 0;\n",
      "     for number = 0 to k - 1\n",
      "         for i = 0 to C[number] - 1\n",
      "             A[pos] = number;\n",
      "             pos = pos + 1;\n",
      "\n",
      " Сортировка сложных объектов \n",
      "Сортировка целых чисел за линейное время это хорошо, но недостаточно. Иногда бывает очень желательно применить быстрый алгоритм сортировки подсчетом для упорядочивания набора каких-либо \"сложных\" данных. Под \"сложными объектами\" здесь подразумеваются структуры, содержащие в себе несколько полей. Одно из них мы выделим и назовем ключом, сортировка будет идти именно по нему (предполагается, что значения, принимаемые ключом  целые числа в диапазоне от 0 до \\mathrm k-1).\n",
      "\n",
      "Мы не сможем использовать здесь в точности тот же алгоритм, что и для сортировки подсчетом обычных целых чисел, потому что в наборе могут быть различные структуры, имеющие одинаковые ключи. Существует два способа справиться с этой проблемой  использовать списки для хранения структур в отсортированном массиве или заранее посчитать количество структур с одинаковыми ключами для каждого значения ключа.  \n",
      "\n",
      " Описание \n",
      "Исходная последовательность из n структур хранится в массиве A, а отсортированная  в массиве B того же размера. Кроме того, используется вспомогательный массив P с индексами от 0 до \\mathrm k-1.\n",
      "\n",
      "Идея алгоритма состоит в предварительном подсчете количества элементов с различными ключами в исходном массиве и разделении результирующего массива на части соответствующей длины (будем называть их блоками). Затем при повторном проходе исходного массива каждый его элемент копируется в специально отведенный его ключу блок, в первую свободную ячейку. Это осуществляется с помощью массива индексов P, в котором хранятся индексы начала блоков для различных ключей. P[key]  индекс в результирующем массиве, соответствующий первому элементу блока для ключа key. \n",
      "\n",
      " Пройдем по исходному массиву A и запишем в P[i] количество структур, ключ которых равен i. \n",
      "Файл:Building_P.png\n",
      "\n",
      " Мысленно разобьем массив B на k блоков, длина каждого из которых равна соответственно P[0], P[1], ..., P[k].\n",
      "Файл:Splitting_B_w_colors.png\n",
      "\n",
      " Теперь массив P нам больше не нужен. Превратим его в массив, хранящий в P[i] сумму элементов от 0 до i-1 старого массива P. \n",
      "Файл:P_after_adding.png\n",
      "\n",
      " Теперь \"сдвинем\" массив P на элемент вперед: в новом массиве P[0] = 0, а для i > 0 P[i] = P_{old}[i-1], где P_{old}  старый массив P.  Это можно сделать за один проход по массиву P, причем одновременно с предыдущим шагом.  После этого действия в массиве P будут хранится индексы массива B. P[key] указывает на начало блока в B, соответствующего ключу key.\n",
      "Файл:P_as_array_of_pointers.png\n",
      "\n",
      " Произведем саму сортировку. Еще раз пройдем по исходному массиву A и для всех i \\in [0, n-1] будем помещать структуру A[i] в массив B на место P[A[i].key], а затем увеличивать P[A[i].key] на 1. Здесь A[i].key  это ключ структуры, находящейся в массиве A на i-том месте. \n",
      "Файл:Sorting_A.png\n",
      "\n",
      "Таким образом после завершения алгоритма в B будет содержаться исходная последовательность в отсортированном виде (так как блоки расположены по возрастанию соответствующих ключей).\n",
      "\n",
      "Стоит также отметить, что эта сортировка является устойчивой, так как два элемента с одинаковыми ключами будут добавлены в том же порядке, в каком просматривались в исходном массиве A. Благодаря этому свойству существует цифровая сортировка.\n",
      "\n",
      " Псевдокод \n",
      "Здесь A и B  массивы структур размера n, с индексами от 0 до n-1.\n",
      "P  целочисленный массив размера k, с индексами от 0 до k-1, где k  количество различных ключей.\n",
      " function complexCountingSort(A: int[n], B: int[n]):\n",
      "     for i = 0 to k - 1\n",
      "         P[i] = 0;         \n",
      "     for i = 0 to length[A] - 1\n",
      "         P[A[i].key] = P[A[i].key] + 1;     \n",
      "     carry = 0;\n",
      "     for i = 0 to k - 1\n",
      "         temporary = P[i];\n",
      "         P[i] = carry;\n",
      "         carry = carry + temporary;     \n",
      "     for i = 0 to length[A] - 1\n",
      "         B[P[A[i].key]] = A[i];\n",
      "         P[A[i].key] = P[A[i].key] + 1;\n",
      "Здесь шаги 3 и 4 из описания объединены в один цикл.\n",
      "Обратите внимание, что в последнем цикле инструкцией\n",
      " B[P[A[i].key]] = A[i];\n",
      "копируется структура A[i] целиком, а не только её ключ.\n",
      "\n",
      " Анализ \n",
      "В первом алгоритме первые два цикла работают за \\Theta(k) и \\Theta(n), соответственно; двойной цикл за \\Theta(n + k). Алгоритм имеет линейную временную трудоёмкость \\Theta(n + k). Используемая дополнительная память равна \\Theta(k).\n",
      "\n",
      "Второй алгоритм состоит из двух проходов по массиву A размера n и одного прохода по массиву P размера k.\n",
      "Его трудоемкость, таким образом, равна \\Theta(n + k). На практике сортировку подсчетом имеет смысл применять, если k = O(n), поэтому можно считать время работы алгоритма равным \\Theta(n). \n",
      "Как и в обычной сортировке подсчетом, требуется \\Theta(n + k) дополнительной памяти  на хранение массива B размера n и массива P размера k.\n",
      "\n",
      "Алгоритм работает за линейное время, но является псевдополиномиальным.\n",
      "\n",
      " Поиск диапазона ключей \n",
      "Если диапазон значений не известен заранее, то его можно найти с помощью линейного поиска минимума и максимума в исходном массиве, что не повлияет на асимптотику алгоритма. \n",
      "Нужно учитывать, что минимум может быть отрицательным, в то время как в массиве P индексы от 0 до k-1. Поэтому при работе с массивом P из исходного A[i]  необходимо вычитать минимум, а при обратной записи в B[i] прибавлять его.\n",
      "\n",
      " Источники информации \n",
      " Сортировка подсчетом  Википедия\n",
      " Counting sort  Wikipedia\n",
      " Кормен Т., Лейзерсон Ч., Ривест Р. Алгоритмы: построение и анализ. — 2-е изд. — М.: Издательский дом «Вильямс», 2007. — С. 224226.\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Другие сортировки\n",
      "Цифровая сортировка (англ. radix sort)  один из алгоритмов сортировки, использующих внутреннюю структуру сортируемых объектов.\n",
      " Алгоритм \n",
      "thumb|right|450px|Пример цифровой сортировки трехзначных чисел, начиная с младших разрядов\n",
      "thumb|right|450px|Пример цифровой сортировки трехзначных чисел, начиная со старших разрядов\n",
      "Имеем множество последовательностей одинаковой длины, состоящих из элементов, на которых задано отношение линейного порядка. Требуется отсортировать эти последовательности в лексикографическом порядке.\n",
      "\n",
      "По аналогии с разрядами чисел будем называть элементы, из которых состоят сортируемые объекты, разрядами. Сам алгоритм состоит в последовательной сортировке объектов какой-либо устойчивой сортировкой по каждому разряду, в порядке от младшего разряда к старшему, после чего последовательности будут расположены в требуемом порядке.\n",
      "\n",
      "Примерами объектов, которые удобно разбивать на разряды и сортировать по ним, являются числа и строки.\n",
      "\n",
      "Для чисел уже существует понятие разряда, поэтому будем представлять числа как последовательности разрядов. Конечно, в разных системах счисления разряды одного и того же числа отличаются, поэтому перед сортировкой представим числа в удобной для нас системе счисления.\n",
      "\n",
      "Строки представляют из себя последовательности символов, поэтому в качестве разрядов в данном случае выступают отдельные символы, сравнение которых обычно происходит по соответствующим им кодам из таблицы кодировок. Для такого разбиения самый младший разряд  последний символ строки.\n",
      "\n",
      "Для вышеперечисленных объектов наиболее часто в качестве устойчивой сортировки применяют сортировку подсчетом.\n",
      "\n",
      "Такой подход к алгоритму называют LSD-сортировкой (Least Significant Digit radix sort). Существует модификация алгоритма цифровой сортировки, анализирующая значения разрядов, начиная слева, с наиболее значащих разрядов. Данный алгоритм известен, как MSD-сортировка (Most Significant Digit radix sort).\n",
      " Корректность алгоритма LSD-сортировки \n",
      "Докажем, что данный алгоритм работает верно, используя метод математической индукции по номеру разряда. Пусть  n   количество разрядов в сортируемых объектах.\n",
      "\n",
      " База:  n = 1 . Очевидно, что алгоритм работает верно, потому что в таком случае мы просто сортируем младшие разряды какой-то заранее выбранной устойчивой сортировкой.\n",
      "\n",
      " Переход: Пусть для  n = k  алгоритм правильно отсортировал последовательности по  k  младшим разрядам. Покажем, что в таком случае, при сортировке по  (k + 1) -му разряду, последовательности также будут отсортированы в правильном порядке. \n",
      "\n",
      "Вспомогательная сортировка разобьет все объекты на группы, в которых  (k + 1) -й разряд объектов одинаковый. Рассмотрим такие группы. Для сортировки по отдельным разрядам мы используем устойчивую сортировку, следовательно порядок объектов с одинаковым  (k + 1) -м разрядом не изменился. Но по предположению индукции по предыдущим  k  разрядам последовательности были отсортированы правильно, и поэтому в каждой такой группе они будут отсортированы верно. Также верно, что сами группы находятся в правильном относительно друг друга порядке, а, следовательно, и все объекты отсортированы правильно по  (k + 1) -м младшим разрядам.\n",
      "\n",
      " Псевдокод \n",
      " LSD-сортировка \n",
      "В качестве примера рассмотрим сортировку чисел. Как говорилось выше, в такой ситуации в качестве устойчивой сортировки применяют сортировку подсчетом, так как обычно количество различных значений разрядов не превосходит количества сортируемых элементов. Ниже приведен псевдокод цифровой сортировки, которой подается массив  A  размера  n   m -разрядных чисел . Сам по себе алгоритм представляет собой цикл по номеру разряда, на каждой итерации которого элементы массива  A  размещаются в нужном порядке во вспомогательном массиве  B . Для подсчета количества объектов,  i -й разряд которых одинаковый, а затем и для определения положения объектов в массиве  B  используется вспомогательный массив  C . Функция  \\mathrm{digit(x, i)}  возвращает  i -й разряд числа  x . Также считаем, что значения разрядов меньше  k .\n",
      "  function radixSort(int[] A):\n",
      "      for i = 1 to m               \n",
      "          for j = 0 to k - 1                              \n",
      "              C[j] = 0                                  \n",
      "          for j = 0 to n - 1\n",
      "              d = digit(A[j], i)\n",
      "              C[d]++\n",
      "          count = 0\n",
      "          for j = 0 to k - 1\n",
      "              tmp = C[j]\n",
      "              C[j] = count\n",
      "              count += tmp\n",
      "          for j = 0 to n - 1\n",
      "              d = digit(A[j], i)                             \n",
      "              B[C[d]] = A[j]            \n",
      "              C[d]++\n",
      "          A = B\n",
      "\n",
      " MSD-сортировка \n",
      "Будем считать, что у всех элементов одинаковое число разрядов. Если это не так, то положим на более старших разрядах элементы с самым маленьким значением — для чисел это 0. Сначала исходный массив делится на k частей, где k — основание, выбранное для представления сортируемых объектов. Эти части принято называть \"корзинами\" или \"карманами\". В первую корзину попадают элементы, у которых старший разряд с номером d = 0 имеет значение 0. Во вторую корзину попадают элементы, у которых старший разряд с номером d = 0 имеет значение 1 и так далее. Затем элементы, попавшие в разные корзины, подвергаются рекурсивному разделению по следующему разряду с номером d = 1. Рекурсивный процесс разделения продолжается, пока не будут перебраны все разряды сортируемых объектов и пока размер корзины больше единицы. То есть останавливаемся когда d > m или l \\geqslant r, где m — максимальное число разрядов в сортируемых объектах, l, r — левая и правая границы отрезка массива A.\n",
      "\n",
      "В основу распределения элементов по корзинам положен метод распределяющего подсчета элементов с одинаковыми значениями в сортируемом разряде. Для этого выполняется просмотр массива и подсчет количества элементов с различными значениями в сортируемом разряде. Эти счетчики фиксируются во вспомогательном массиве счетчиков cnt. Затем счетчики используются для вычисления размеров корзин и определения границ разделения массива. В соответствии с этими границами сортируемые объекты переносятся во вспомогательный массив c, в котором размещены корзины.\n",
      "После того как корзины сформированы, содержимое вспомогательного массива c переносится обратно в исходный массив A и выполняется рекурсивное разделение новых частей по следующему разряду в пределах границ корзин, полученных на предыдущем шаге.\n",
      "\n",
      "Изначально запускаем функцию так \n",
      "\n",
      "  function radixSort(int[] A, int l, int r, int d):\n",
      "      if d > m or l >= r \n",
      "          return\n",
      "      for j = 0 to k + 1 \n",
      "          cnt[j] = 0\n",
      "      for i = l to r                              \n",
      "          j = digit(A[i], d)\n",
      "          cnt[j + 1]++\n",
      "      for j = 2 to k\n",
      "          cnt[j] += cnt[j - 1]\n",
      "      for i = l to r\n",
      "          j = digit(A[i], d)\n",
      "          c[l + cnt[j]] = A[i]\n",
      "          cnt[j]--\n",
      "      for i = l to r\n",
      "          A[i] = c[i]\n",
      "      radixSort(A, l, l + cnt[0] - 1, d + 1)\n",
      "      for i = 1 to k\n",
      "          radixSort(A, l + cnt[i - 1], l + cnt[i] - 1, d + 1)\n",
      "\n",
      "Сложность\n",
      "Сложность LSD-сортировки\n",
      "Пусть  m   количество разрядов,  n   количество объектов, которые нужно отсортировать,  T(n)   время работы устойчивой сортировки. Цифровая сортировка выполняет  k  итераций, на каждой из которой выполняется устойчивая сортировка и не более  O(1)  других операций. Следовательно время работы цифровой сортировки   O(k T(n)) .\n",
      "\n",
      "Рассмотрим отдельно случай сортировки чисел. Пусть в качестве аргумента сортировке передается массив, в котором содержатся  n   m -значных чисел, и каждая цифра может принимать значения от  0  до  k - 1 . Тогда цифровая сортировка позволяет отсортировать данный массив за время  O(m (n + k)) , если устойчивая сортировка имеет время работы  O(n + k) . Если  k  небольшое, то оптимально выбирать в качестве устойчивой сортировки сортировку подсчетом.\n",
      "\n",
      "Если количество разрядов  константа, а  k = O(n) , то сложность цифровой сортировки составляет  O(n) , то есть она линейно зависит от количества сортируемых чисел.\n",
      "Сложность MSD-сортировки\n",
      "Пусть значения разрядов меньше b, а количество разрядов  k. При сортировке массива из одинаковых элементов MSD-сортировкой на каждом шаге все элементы будут находится в неубывающей по размеру корзине, а так как цикл идет по всем элементам массива, то получим, что время работы MSD-сортировки оценивается величиной O(nk), причем это время нельзя улучшить. Хорошим случаем для данной сортировки будет массив, при котором на каждом шаге каждая корзина будет делиться на b частей. Как только размер корзины станет равен 1, сортировка перестанет рекурсивно запускаться в этой корзине. Таким образом, асимптотика будет . Это хорошо тем, что не зависит от числа разрядов.\n",
      "\n",
      "Существует также модификация MSD-сортировки, при которой рекурсивный процесс останавливается при небольших размерах текущего кармана, и вызывается более быстрая сортировка, основанная на сравнениях (например, сортировка вставками).\n",
      "\n",
      " См. также \n",
      " Сортировка подсчетом\n",
      " Сортировка вставками\n",
      "\n",
      " Источники информации \n",
      " Википедия  Цифровая сортировка\n",
      " Визуализатор 1 — Java-аплет.\n",
      " Визуализатор 2 — Java-аплет.\n",
      " Дональд Кнут Искусство программирования, том 3. Сортировка и поиск\n",
      " Кормен, Т., Лейзерсон, Ч., Ривест, Р., Штайн, К. Алгоритмы: построение и анализ\n",
      "\n",
      "Категория: Дискретная математика и алгоритмы\n",
      "Категория: Сортировки\n",
      "Категория: Другие сортировки\n",
      " Модификация QuickSort \n",
      " Описание алгоритма \n",
      "\n",
      "Будем использовать процедуру рассечения массива элементов из алгоритма сортировки QuickSort. Пусть нам надо найти k-ую порядковую статистику, а после рассечения опорный элемент встал на позицию m. Возможно три случая:\n",
      "\n",
      " k = m. Порядковая статистика найдена.\n",
      " k < m. Рекурсивно ищем k-ую статистику в первой части массива.\n",
      " k > m. Рекурсивно ищем (k - m - 1)-ую статистику во второй части массива.\n",
      "\n",
      " Код алгоритма \n",
      "\n",
      "Ниже представлен код представленного алгоритма. При реализации, однако, вместо рекурсивных вызовов изменяются границы поиска статистики во внешнем цикле. В коде считаем, что процедура partition принимает массив и границы отрезка, который будет рассечён (причём правая граница отрезка не включается), и возвращает индекс опорного элемента. Также считается, что массив индексируется с нуля.\n",
      "\n",
      " int findOrderStatistic(int[] array, int k) {\n",
      "   int left = 0, right = array.length;\n",
      "   while (true) {\n",
      "     int mid = partition(array, left, right);\n",
      " \n",
      "     if (mid == k) {\n",
      "       return array[mid];\n",
      "     }\n",
      "     else if (k < mid) {\n",
      "       right = mid;\n",
      "     }\n",
      "     else {\n",
      "       left = mid + 1;\n",
      "     }\n",
      "   }\n",
      " }\n",
      "\n",
      " Анализ времени работы \n",
      "\n",
      "Аналогично QuickSort, может возникнуть такой же худший случай (процедура partition возвращает каждый раз левую или правую границу рассматриваемой части), при котором время работы составит \\Omega(n^2). Однако, если считать, что partition возвращает все элементы рассматриваемого отрезка с равной вероятностью, то можно оценить матожидание времени работы как O(n).\n",
      "\n",
      "Будем оценивать количество сравнений. При поиске статистики в массиве размера n функция partition (точнее, одна из распространённых вариаций) совершает не более n - 1 сравнений. Далее, в зависимости от k выбирается левая или правая половины (или вообще алгоритм завершает работу). Оценку проводим сверху, то есть, будем считать, что каждый раз выбирается большая половина.\n",
      "\n",
      "T(n) \\le \\frac 1n \\sum\\limits_{k = 1}^n \\left ( T \\left ( \\max \\left \\{k - 1; n - k \\right \\} \\right ) + n - 1 \\right ) =\n",
      "= n - 1 + \\frac 1n \\sum\\limits_{k = 1}^n T(\\max \\{k - 1; n - k\\}) = n - 1 + \\frac 2n \\sum\\limits_{k = \\lfloor n/2 \\rfloor}^{n - 1} T(k)\n",
      "\n",
      "Предположим, что T(k) \\le ck для некоторой константы c и всех k < n (будем доказывать оценку по индукции). Тогда верно неравенство:\n",
      "\n",
      "T(n) = n - 1 + \\frac 2n \\sum\\limits_{k = \\lfloor n/2 \\rfloor}^{n - 1} ck\n",
      "\n",
      "Преобразуем сумму из правой части равенства по формуле суммы арифметической прогрессии и оценим преобразованное выражение:\n",
      "\n",
      "\\sum\\limits_{k = \\lfloor n/2 \\rfloor}^{n - 1} ck = \\frac 12 \\left (\\left \\lceil \\frac n2 \\right \\rceil - 1 \\right) \\left( c \\left \\lfloor \\frac n2 \\right \\rfloor + c(n - 1) \\right ) \\le \\frac c2 \\left (\\frac{n + 1}2 - 1\\right) \\frac{3n - 2}2 = c \\frac{n - 1}4 \\frac{3n - 2}2\n",
      "\n",
      "Воспользуемся полученной оценкой для оценки исходного выражения. Также, предположим, что c \\ge 4:\n",
      "\n",
      "T(n) \\le n - 1 + \\frac{2c}n \\frac{n - 1}4 \\frac{3n - 2}2 = n - 1 + c\\frac{n - 1}{2n} \\frac{3n - 2}2 \\le \\frac c4 (n - 1) + \\frac c4\\left (\\frac{n - 1}n (3n - 2)\\right) \\le\n",
      "\\le \\frac c4 (n - 1 + 3n - 2) = \\frac c4 (4n - 3) \\le cn\n",
      "\n",
      "Для довершения доказательства необходима проверка базы индукции, но она тривиальна: для выборки порядковой статистики из одного элемента сравнений не требуется: T(1) = 0 < 4. Итого, мы доказали, что T(n) \\le 4n, следовательно, T(n) = O(n)\n",
      "\n",
      " Ссылки \n",
      " Selection algorithm — Wikipedia\n",
      " Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Third Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Section 5.3.3: Minimum-Comparison Selection, pp.207–219.\n"
     ]
    }
   ],
   "source": [
    "content = get_content(sorting_titles)\n",
    "write_to_file(content, \"text_db/sorting.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
